{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Text_Summarization.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"LTleiuNyW-O4","colab_type":"code","outputId":"153d0f66-a588-4a8c-d37e-a8a14a0dccbc","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1556960861722,"user_tz":-330,"elapsed":15062,"user":{"displayName":"arpit.jain arpit.jain","photoUrl":"https://lh5.googleusercontent.com/-cBrzJn4bZ70/AAAAAAAAAAI/AAAAAAAAA4k/GAn2TH00IbM/s64/photo.jpg","userId":"08694739481247522869"}}},"source":["#Code Written By-\n","# Arpit Jain , Gautam Yadav, Narosenla Longkumer\n","\n","#Referred From-\n","#thomasschmied (GitHub)\n","\n","import os\n","import time\n","import re\n","import html\n","from collections import Counter\n","\n","import nltk\n","import numpy as np\n","\n","\n","def preprocess_sentence(text, keep_most=False):\n","    \"\"\"\n","    Helper function to remove html, unneccessary spaces and punctuation.\n","    Args:\n","        text: String.\n","        keep_most: Boolean. depending if True or False, we either\n","                   keep only letters and numbers or also other characters.\n","\n","    Returns:\n","        processed text.\n","\n","    \"\"\"\n","    text = text.lower()\n","    text = fixup(text)\n","    text = re.sub(r\"<br />\", \" \", text)\n","    if keep_most:\n","        text = re.sub(r\"[^a-z0-9%!?.,:()/]\", \" \", text)\n","    else:\n","        text = re.sub(r\"[^a-z0-9]\", \" \", text)\n","    text = re.sub(r\"    \", \" \", text)\n","    text = re.sub(r\"   \", \" \", text)\n","    text = re.sub(r\"  \", \" \", text)\n","    text = re.sub(r\"\\b[a-zA-Z]\\b\", \"\", text)\n","    text = text.strip()\n","    return text\n","\n","\n","def fixup(x):\n","    re1 = re.compile(r'  +')\n","    x = x.replace('#39;', \"'\").replace('amp;', '&').replace('#146;', \"'\").replace(\n","        'nbsp;', ' ').replace('#36;', '$').replace('\\\\n', \"\\n\").replace('quot;', \"'\").replace(\n","        '<br />', \"\\n\").replace('\\\\\"', '\"').replace('<unk>', 'u_n').replace(' @.@ ', '.').replace(\n","        ' @-@ ', '-').replace('\\\\', ' \\\\ ')\n","    return re1.sub(' ', html.unescape(x))\n","\n","\n","def preprocess(text, keep_most=False):\n","    \"\"\"\n","    Splits the text into sentences, preprocesses\n","       and tokenizes each sentence.\n","    Args:\n","        text: String. multiple sentences.\n","        keep_most: Boolean. depending if True or False, we either\n","                   keep only letters and numbers or also other characters.\n","\n","    Returns:\n","        preprocessed and tokenized text.\n","\n","    \"\"\"\n","    tokenized = []\n","    for sentence in nltk.sent_tokenize(text):\n","        sentence = preprocess_sentence(sentence, keep_most)\n","        sentence = nltk.word_tokenize(sentence)\n","        for token in sentence:\n","            tokenized.append(token)\n","\n","    return tokenized\n","\n","\n","def preprocess_texts_and_summaries(texts,\n","                                   summaries,\n","                                   keep_most=False):\n","    \"\"\"iterates given list of texts and given list of summaries and tokenizes every\n","       review using the tokenize_review() function.\n","       apart from that we count up all the words in the texts and summaries.\n","       returns: - processed texts\n","                - processed summaries\n","                - array containing all the unique words together with their counts\n","                  sorted by counts.\n","    \"\"\"\n","\n","    start_time = time.time()\n","    processed_texts = []\n","    processed_summaries = []\n","    words = []\n","\n","    for text in texts:\n","        text = preprocess(text, keep_most)\n","        for word in text:\n","            words.append(word)\n","        processed_texts.append(text)\n","    for summary in summaries:\n","        summary = preprocess(summary, keep_most)\n","        for word in summary:\n","            words.append(word)\n","\n","        processed_summaries.append(summary)\n","    words_counted = Counter(words).most_common()\n","    print('Processing Time: ', time.time() - start_time)\n","\n","    return processed_texts, processed_summaries, words_counted\n","\n","\n","def create_word_inds_dicts(words_counted,\n","                           specials=None,\n","                           min_occurences=0):\n","    \"\"\" creates lookup dicts from word to index and back.\n","        returns the lookup dicts and an array of words that were not used,\n","        due to rare occurence.\n","    \"\"\"\n","    missing_words = []\n","    word2ind = {}\n","    ind2word = {}\n","    i = 0\n","\n","    if specials is not None:\n","        for sp in specials:\n","            word2ind[sp] = i\n","            ind2word[i] = sp\n","            i += 1\n","\n","    for (word, count) in words_counted:\n","        if count >= min_occurences and (count >= 2 or len(word) > 2):\n","            word2ind[word] = i\n","            ind2word[i] = word\n","            i += 1        \n","        else:\n","            missing_words.append(word)\n","\n","    return word2ind, ind2word, missing_words\n","\n","\n","def convert_sentence(review, word2ind):\n","    \"\"\" converts the given sent to int values corresponding to the given word2ind\"\"\"\n","    inds = []\n","    unknown_words = []\n","\n","    for word in review:\n","        if word in word2ind.keys():\n","            inds.append(int(word2ind[word]))\n","        else:\n","            inds.append(int(word2ind['<UNK>']))\n","            unknown_words.append(word)\n","\n","    return inds, unknown_words\n","\n","\n","def convert_to_inds(input, word2ind, eos=False, sos=False):\n","    converted_input = []\n","    all_unknown_words = set()\n","\n","    for inp in input:\n","        converted_inp, unknown_words = convert_sentence(inp, word2ind)\n","        if eos:\n","            converted_inp.append(word2ind['<EOS>'])\n","        if sos:\n","            converted_inp.insert(0, word2ind['<SOS>'])\n","        converted_input.append(converted_inp)\n","        all_unknown_words.update(unknown_words)\n","\n","    return converted_input, all_unknown_words\n","\n","\n","def convert_inds_to_text(inds, ind2word, preprocess=False):\n","    \"\"\" convert the given indexes back to text \"\"\"\n","    words = [ind2word[word] for word in inds]\n","    return words\n","\n","\n","def load_pretrained_embeddings(path):\n","    \"\"\"loads pretrained embeddings. stores each embedding in a\n","       dictionary with its corresponding word\n","    \"\"\"\n","    embeddings = {}\n","    with open(path, 'r', encoding='utf-8') as f:\n","        for line in f:\n","            values = line.split(' ')\n","            word = values[0]\n","            embedding_vector = np.array(values[1:], dtype='float32')\n","            embeddings[word] = embedding_vector\n","    return embeddings\n","\n","\n","def create_and_save_embedding_matrix(word2ind,\n","                                     pretrained_embeddings_path,\n","                                     save_path,\n","                                     embedding_dim=300):\n","    \"\"\"creates embedding matrix for each word in word2ind. if that words is in\n","       pretrained_embeddings, that vector is used. otherwise initialized\n","       randomly.\n","    \"\"\"\n","    pretrained_embeddings = load_pretrained_embeddings(pretrained_embeddings_path)\n","    embedding_matrix = np.zeros((len(word2ind), embedding_dim), dtype=np.float32)\n","    for word, i in word2ind.items():\n","        if word in pretrained_embeddings.keys():\n","            embedding_matrix[i] = pretrained_embeddings[word]\n","        else:\n","            embedding = np.array(np.random.uniform(-1.0, 1.0, embedding_dim))\n","            embedding_matrix[i] = embedding\n","    if not os.path.exists(os.path.dirname(save_path)):\n","        os.makedirs(os.path.dirname(save_path))\n","    np.save(save_path, embedding_matrix)\n","    return np.array(embedding_matrix)\n","\n","import numpy as np\n","import tensorflow as tf\n","from nltk.translate.bleu_score import sentence_bleu\n","!pip install rouge\n","from rouge import Rouge\n","\n","\n","\n","def minibatches(inputs, targets, minibatch_size):\n","    \"\"\"batch generator. yields x and y batch.\n","    \"\"\"\n","    x_batch, y_batch = [], []\n","    for inp, tgt in zip(inputs, targets):\n","        if len(x_batch) == minibatch_size and len(y_batch) == minibatch_size:\n","            yield x_batch, y_batch\n","            x_batch, y_batch = [], []\n","        x_batch.append(inp)\n","        y_batch.append(tgt)\n","\n","    if len(x_batch) != 0:\n","        for inp, tgt in zip(inputs, targets):\n","            if len(x_batch) != minibatch_size:\n","                x_batch.append(inp)\n","                y_batch.append(tgt)\n","            else:\n","                break\n","        yield x_batch, y_batch\n","\n","\n","def pad_sequences(sequences, pad_tok, tail=True):\n","    \"\"\"Pads the sentences, so that all sentences in a batch have the same length.\n","    \"\"\"\n","\n","    max_length = max(len(x) for x in sequences)\n","\n","    sequence_padded, sequence_length = [], []\n","\n","    for seq in sequences:\n","        seq = list(seq)\n","        if tail:\n","            seq_ = seq[:max_length] + [pad_tok] * max(max_length - len(seq), 0)\n","        else:\n","            seq_ = [pad_tok] * max(max_length - len(seq), 0) + seq[:max_length]\n","\n","        sequence_padded += [seq_]\n","        sequence_length += [min(len(seq), max_length)]\n","\n","    return sequence_padded, sequence_length\n","\n","\n","def sample_results(preds, ind2word, word2ind, converted_summaries, converted_texts, use_rouge = False, use_bleu=False):\n","    \"\"\"Plots the actual text and summary and the corresponding created summary.\n","    takes care of whether beam search or greedy decoder was used.\n","    \"\"\"\n","    beam = False\n","\n","    if len(np.array(preds).shape) == 4:\n","        beam = True\n","\n","    '''Bleu score is not used correctly here, but serves as reference.\n","    '''\n","    if use_bleu:\n","        bleu_scores = []\n","        \n","    if use_rouge:\n","        rouge_scores = []\n","\n","    for pred, summary, text, seq_length in zip(preds[0],\n","                                               converted_summaries,\n","                                               converted_texts,\n","                                               [len(inds) for inds in converted_summaries]):\n","        print('\\n\\n\\n', 100 * '-')\n","        if beam:\n","            actual_text = [ind2word[word] for word in text if\n","                           word != word2ind[\"<SOS>\"] and word != word2ind[\"<EOS>\"]]\n","            actual_summary = [ind2word[word] for word in summary if\n","                              word != word2ind['<EOS>'] and word != word2ind['<SOS>']]\n","\n","            created_summary = []\n","            for word in pred:\n","                if word[0] != word2ind['<SOS>'] and word[0] != word2ind['<EOS>']:\n","                    created_summary.append(ind2word[word[0]])\n","                    continue\n","                else:\n","                    continue\n","\n","            print('Actual Text:\\n{}\\n'.format(' '.join(actual_text)))\n","            print('Actual Summary:\\n{}\\n'.format(' '.join(actual_summary)))\n","            print('Created Summary:\\n{}\\n'.format(' '.join(created_summary)))\n","            if use_rouge:\n","                rouge = Rouge()\n","                rogue_score = rouge.get_scores(' '.join(created_summary), ' '.join(actual_summary), avg=True)\n","                type(rogue_score)\n","                rouge_scores.append(rogue_score)\n","                print('Rogue-score:', rogue_score)\n","            if use_bleu:\n","                bleu_score = sentence_bleu([actual_summary], created_summary)\n","                bleu_scores.append(bleu_score)\n","                print('Bleu-score:', bleu_score)\n","\n","            print()\n","\n","\n","        else:\n","            actual_text = [ind2word[word] for word in text if\n","                           word != word2ind[\"<SOS>\"] and word != word2ind[\"<EOS>\"]]\n","            actual_summary = [ind2word[word] for word in summary if\n","                              word != word2ind['<EOS>'] and word != word2ind['<SOS>']]\n","            created_summary = [ind2word[word] for word in pred if\n","                               word != word2ind['<EOS>'] and word != word2ind['<SOS>']]\n","\n","            print('Actual Text:\\n{}\\n'.format(' '.join(actual_text)))\n","            print('Actual Summary:\\n{}\\n'.format(' '.join(actual_summary)))\n","            print('Created Summary:\\n{}\\n'.format(' '.join(created_summary)))\n","            if use_rouge:\n","                rouge = Rouge()\n","                rogue_score = rouge.get_scores(' '.join(created_summary), ' '.join(actual_summary), avg=True)\n","                rouge_scores.append(rogue_score)\n","                print(actual_summary)\n","                print('Rogue-score:', rogue_score)\n","            if use_bleu:\n","                bleu_score = sentence_bleu([actual_summary], created_summary)\n","                bleu_scores.append(bleu_score)\n","                print('Bleu-score:', bleu_score)\n","\n","    #To print average ROUGE SCORES\n","    f1=p1=r1=0\n","    f2=p2=r2=0\n","    fl=pl=rl=0\n","    l=len(rouge_scores)\n","\n","    for r in rouge_scores:\n","        f1=f1+r['rouge-1']['f']\n","        p1=p1+r['rouge-1']['p']\n","        r1=r1+r['rouge-1']['r']\n","        f2=f2+r['rouge-2']['f']\n","        p2=p2+r['rouge-2']['p']\n","        r2=r2+r['rouge-2']['r']\n","        fl=fl+r['rouge-l']['f']\n","        pl=pl+r['rouge-l']['p']\n","        rl=rl+r['rouge-l']['r']\n","\n","    print(\"\\nAverage Rouge (Recall-Oriented Understudy for Gisting Evaluation) Scores:\\n\")\n","    print(\"ROUGE-1: \\n\")\n","    print(\"Precision: \",p1/l)\n","    print(\"Recall: \",r1/l)\n","    print(\"F-Score: \",f1/l)\n","    print(\"\\nROUGE-2: \\n\")\n","    print(\"Precision: \",p2/l)\n","    print(\"Recall: \",r2/l)\n","    print(\"F-Score: \",f2/l)\n","    print(\"\\nROUGE-L: \\n\")\n","    print(\"Precision: \",pl/l)\n","    print(\"Recall: \",rl/l)\n","    print(\"F-Score: \",fl/l)\n","    \n","    if use_bleu:\n","        bleu_score = np.mean(bleu_scores)\n","        print('\\n\\n\\nTotal Bleu Score:', bleu_score)\n","\n","\n","def reset_graph(seed=97):\n","    \"\"\"helper function to reset the default graph. this often\n","       comes handy when using jupyter noteboooks.\n","    \"\"\"\n","    tf.reset_default_graph()\n","    tf.set_random_seed(seed)\n","    np.random.seed(seed)\n","\n","\n","\n","\n","import os\n","import numpy as np\n","\n","import tensorflow as tf\n","from tensorflow.python.layers.core import Dense\n","\n","\n","class Summarizer:\n","\n","    def __init__(self,\n","                 word2ind,\n","                 ind2word,\n","                 save_path,\n","                 mode='TRAIN',\n","                 num_layers_encoder=1,\n","                 num_layers_decoder=1,\n","                 embedding_dim=300,\n","                 rnn_size_encoder=256,\n","                 rnn_size_decoder=256,\n","                 learning_rate=0.001,\n","                 learning_rate_decay=0.9,\n","                 learning_rate_decay_steps=100,\n","                 max_lr=0.01,\n","                 keep_probability=0.8,\n","                 batch_size=64,\n","                 beam_width=10,\n","                 epochs=20,\n","                 eos=\"<EOS>\",\n","                 sos=\"<SOS>\",\n","                 pad='<PAD>',\n","                 clip=5,\n","                 inference_targets=False,\n","                 pretrained_embeddings_path=None,\n","                 summary_dir=None,\n","                 use_cyclic_lr=False):\n","        \"\"\"\n","\n","        Args:\n","            word2ind: lookup dict from word to index.\n","            ind2word: lookup dict from index to word.\n","            save_path: path to save the tf model to in the end.\n","            mode: String. 'TRAIN' or 'INFER'. depending on which mode we use\n","                  a different graph is created.\n","            num_layers_encoder: Float. Number of encoder layers. defaults to 1.\n","            num_layers_decoder: Float. Number of decoder layers. defaults to 1.\n","            embedding_dim: dimension of the embedding vectors in the embedding matrix.\n","                           every word has a embedding_dim 'long' vector.\n","            rnn_size_encoder: Integer. number of hidden units in encoder. defaults to 256.\n","            rnn_size_decoder: Integer. number of hidden units in decoder. defaults to 256.\n","            learning_rate: Float.\n","            learning_rate_decay: only if exponential learning rate is used.\n","            learning_rate_decay_steps: Integer.\n","            max_lr: only used if cyclic learning rate is used.\n","            keep_probability: Float.\n","            batch_size: Integer. Size of minibatches.\n","            beam_width: Integer. Only used in inference, for Beam Search.('INFER'-mode)\n","            epochs: Integer. Number of times the training is conducted\n","                    on the whole training data.\n","            eos: EndOfSentence tag.\n","            sos: StartOfSentence tag.\n","            pad: Padding tag.\n","            clip: Value to clip the gradients to in training process.\n","            inference_targets:\n","            pretrained_embeddings_path: Path to pretrained embeddings. Has to be .npy\n","            summary_dir: Directory the summaries are written to for tensorboard.\n","            use_cyclic_lr: Boolean.\n","        \"\"\"\n","\n","        self.word2ind = word2ind\n","        self.ind2word = ind2word\n","        self.vocab_size = len(word2ind)\n","        self.num_layers_encoder = num_layers_encoder\n","        self.num_layers_decoder = num_layers_decoder\n","        self.rnn_size_encoder = rnn_size_encoder\n","        self.rnn_size_decoder = rnn_size_decoder\n","        self.save_path = save_path\n","        self.embedding_dim = embedding_dim\n","        self.mode = mode.upper()\n","        self.learning_rate = learning_rate\n","        self.learning_rate_decay = learning_rate_decay\n","        self.learning_rate_decay_steps = learning_rate_decay_steps\n","        self.keep_probability = keep_probability\n","        self.batch_size = batch_size\n","        self.beam_width = beam_width\n","        self.eos = eos\n","        self.sos = sos\n","        self.clip = clip\n","        self.pad = pad\n","        self.epochs = epochs\n","        self.inference_targets = inference_targets\n","        self.pretrained_embeddings_path = pretrained_embeddings_path\n","        self.use_cyclic_lr = use_cyclic_lr\n","        self.max_lr = max_lr\n","        self.summary_dir = summary_dir\n","\n","    def build_graph(self):\n","        self.add_placeholders()\n","        self.add_embeddings()\n","        self.add_lookup_ops()\n","        self.initialize_session()\n","        self.add_seq2seq()\n","        self.saver = tf.train.Saver()\n","        print('Graph built.')\n","\n","    def add_placeholders(self):\n","        self.ids_1 = tf.placeholder(tf.int32,\n","                                    shape=[None, None],\n","                                    name='ids_source')\n","        self.ids_2 = tf.placeholder(tf.int32,\n","                                    shape=[None, None],\n","                                    name='ids_target')\n","        self.sequence_lengths_1 = tf.placeholder(tf.int32,\n","                                                 shape=[None],\n","                                                 name='sequence_length_source')\n","        self.sequence_lengths_2 = tf.placeholder(tf.int32,\n","                                                 shape=[None],\n","                                                 name='sequence_length_target')\n","        self.maximum_iterations = tf.reduce_max(self.sequence_lengths_2,\n","                                                name='max_dec_len')\n","\n","    def create_word_embedding(self, embed_name, vocab_size, embed_dim):\n","        \"\"\"Creates embedding matrix in given shape - [vocab_size, embed_dim].\n","        \"\"\"\n","        embedding = tf.get_variable(embed_name,\n","                                    shape=[vocab_size, embed_dim],\n","                                    dtype=tf.float32)\n","        return embedding\n","\n","    def add_embeddings(self):\n","        \"\"\"Creates the embedding matrix. In case path to pretrained embeddings is given,\n","           that embedding is loaded. Otherwise created.\n","        \"\"\"\n","        if self.pretrained_embeddings_path is not None:\n","            self.embedding = tf.Variable(np.load(self.pretrained_embeddings_path),\n","                                         name='embedding')\n","            print('Loaded pretrained embeddings.')\n","        else:\n","            self.embedding = self.create_word_embedding('embedding',\n","                                                        self.vocab_size,\n","                                                        self.embedding_dim)\n","\n","    def add_lookup_ops(self):\n","        \"\"\"Additional lookup operation for both source embedding and target embedding matrix.\n","        \"\"\"\n","        self.word_embeddings_1 = tf.nn.embedding_lookup(self.embedding,\n","                                                        self.ids_1,\n","                                                        name='word_embeddings_1')\n","        self.word_embeddings_2 = tf.nn.embedding_lookup(self.embedding,\n","                                                        self.ids_2,\n","                                                        name='word_embeddings_2')\n","\n","    def make_rnn_cell(self, rnn_size, keep_probability):\n","        \"\"\"Creates LSTM cell wrapped with dropout.\n","        \"\"\"\n","        cell = tf.nn.rnn_cell.LSTMCell(rnn_size)\n","        cell = tf.nn.rnn_cell.DropoutWrapper(cell, input_keep_prob=keep_probability)\n","        return cell\n","\n","    def make_attention_cell(self, dec_cell, rnn_size, enc_output, lengths, alignment_history=False):\n","        \"\"\"Wraps the given cell with Bahdanau Attention.\n","        \"\"\"\n","        attention_mechanism = tf.contrib.seq2seq.BahdanauAttention(num_units=rnn_size,\n","                                                                   memory=enc_output,\n","                                                                   memory_sequence_length=lengths,\n","                                                                   name='BahdanauAttention')\n","\n","        return tf.contrib.seq2seq.AttentionWrapper(cell=dec_cell,\n","                                                   attention_mechanism=attention_mechanism,\n","                                                   attention_layer_size=None,\n","                                                   output_attention=False,\n","                                                   alignment_history=alignment_history)\n","\n","    def triangular_lr(self, current_step):\n","        \"\"\"cyclic learning rate - exponential range.\"\"\"\n","        step_size = self.learning_rate_decay_steps\n","        base_lr = self.learning_rate\n","        max_lr = self.max_lr\n","\n","        cycle = tf.floor(1 + current_step / (2 * step_size))\n","        x = tf.abs(current_step / step_size - 2 * cycle + 1)\n","        lr = base_lr + (max_lr - base_lr) * tf.maximum(0.0, tf.cast((1.0 - x), dtype=tf.float32)) * (0.99999 ** tf.cast(\n","            current_step,\n","            dtype=tf.float32))\n","        return lr\n","\n","\n","    def add_seq2seq(self):\n","        \"\"\"Creates the sequence to sequence architecture.\"\"\"\n","        with tf.variable_scope('dynamic_seq2seq', dtype=tf.float32):\n","            # Encoder\n","            encoder_outputs, encoder_state = self.build_encoder()\n","\n","            # Decoder\n","            logits, sample_id, final_context_state = self.build_decoder(encoder_outputs,\n","                                                                        encoder_state)\n","            if self.mode == 'TRAIN':\n","\n","                # Loss\n","                loss = self.compute_loss(logits)\n","                self.train_loss = loss\n","                self.eval_loss = loss\n","                self.global_step = tf.Variable(0, trainable=False)\n","\n","\n","                # cyclic learning rate\n","                if self.use_cyclic_lr:\n","                    self.learning_rate = self.triangular_lr(self.global_step)\n","\n","                # exponential learning rate\n","                else:\n","                    self.learning_rate = tf.train.exponential_decay(\n","                        self.learning_rate,\n","                        self.global_step,\n","                        decay_steps=self.learning_rate_decay_steps,\n","                        decay_rate=self.learning_rate_decay,\n","                        staircase=True)\n","\n","                # Optimizer\n","                opt = tf.train.AdamOptimizer(self.learning_rate)\n","\n","\n","                # Gradients\n","                if self.clip > 0:\n","                    grads, vs = zip(*opt.compute_gradients(self.train_loss))\n","                    grads, _ = tf.clip_by_global_norm(grads, self.clip)\n","                    self.train_op = opt.apply_gradients(zip(grads, vs),\n","                                                        global_step=self.global_step)\n","                else:\n","                    self.train_op = opt.minimize(self.train_loss,\n","                                                 global_step=self.global_step)\n","\n","\n","\n","            elif self.mode == 'INFER':\n","                loss = None\n","                self.infer_logits, _, self.final_context_state, self.sample_id = logits, loss, final_context_state, sample_id\n","                self.sample_words = self.sample_id\n","\n","    def build_encoder(self):\n","        \"\"\"The encoder. Bidirectional LSTM.\"\"\"\n","\n","        with tf.variable_scope(\"encoder\"):\n","            fw_cell = self.make_rnn_cell(self.rnn_size_encoder // 2, self.keep_probability)\n","            bw_cell = self.make_rnn_cell(self.rnn_size_encoder // 2, self.keep_probability)\n","\n","            for _ in range(self.num_layers_encoder):\n","                (out_fw, out_bw), (state_fw, state_bw) = tf.nn.bidirectional_dynamic_rnn(\n","                    cell_fw=fw_cell,\n","                    cell_bw=bw_cell,\n","                    inputs=self.word_embeddings_1,\n","                    sequence_length=self.sequence_lengths_1,\n","                    dtype=tf.float32)\n","                encoder_outputs = tf.concat((out_fw, out_bw), -1)\n","\n","            bi_state_c = tf.concat((state_fw.c, state_bw.c), -1)\n","            bi_state_h = tf.concat((state_fw.h, state_bw.h), -1)\n","            bi_lstm_state = tf.nn.rnn_cell.LSTMStateTuple(c=bi_state_c, h=bi_state_h)\n","            encoder_state = tuple([bi_lstm_state] * self.num_layers_encoder)\n","\n","            return encoder_outputs, encoder_state\n","\n","\n","    def build_decoder(self, encoder_outputs, encoder_state):\n","\n","        sos_id_2 = tf.cast(self.word2ind[self.sos], tf.int32)\n","        eos_id_2 = tf.cast(self.word2ind[self.eos], tf.int32)\n","        self.output_layer = Dense(self.vocab_size, name='output_projection')\n","\n","        # Decoder.\n","        with tf.variable_scope(\"decoder\") as decoder_scope:\n","\n","            cell, decoder_initial_state = self.build_decoder_cell(\n","                encoder_outputs,\n","                encoder_state,\n","                self.sequence_lengths_1)\n","\n","            # Train\n","            if self.mode != 'INFER':\n","\n","                helper = tf.contrib.seq2seq.ScheduledEmbeddingTrainingHelper(\n","                    inputs=self.word_embeddings_2,\n","                    sequence_length=self.sequence_lengths_2,\n","                    embedding=self.embedding,\n","                    sampling_probability=0.5,\n","                    time_major=False)\n","\n","                # Decoder\n","                my_decoder = tf.contrib.seq2seq.BasicDecoder(cell,\n","                                                             helper,\n","                                                             decoder_initial_state,\n","                                                             output_layer=self.output_layer)\n","\n","                # Dynamic decoding\n","                outputs, final_context_state, _ = tf.contrib.seq2seq.dynamic_decode(\n","                    my_decoder,\n","                    output_time_major=False,\n","                    maximum_iterations=self.maximum_iterations,\n","                    swap_memory=False,\n","                    impute_finished=True,\n","                    scope=decoder_scope\n","                )\n","\n","                sample_id = outputs.sample_id\n","                logits = outputs.rnn_output\n","\n","\n","            # Inference\n","            else:\n","                start_tokens = tf.fill([self.batch_size], sos_id_2)\n","                end_token = eos_id_2\n","\n","                # beam search\n","                if self.beam_width > 0:\n","                    my_decoder = tf.contrib.seq2seq.BeamSearchDecoder(\n","                        cell=cell,\n","                        embedding=self.embedding,\n","                        start_tokens=start_tokens,\n","                        end_token=end_token,\n","                        initial_state=decoder_initial_state,\n","                        beam_width=self.beam_width,\n","                        output_layer=self.output_layer,\n","                    )\n","\n","                # greedy\n","                else:\n","                    helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(self.embedding,\n","                                                                      start_tokens,\n","                                                                      end_token)\n","\n","                    my_decoder = tf.contrib.seq2seq.BasicDecoder(cell,\n","                                                                 helper,\n","                                                                 decoder_initial_state,\n","                                                                 output_layer=self.output_layer)\n","                if self.inference_targets:\n","                    maximum_iterations = self.maximum_iterations\n","                else:\n","                    maximum_iterations = None\n","\n","                # Dynamic decoding\n","                outputs, final_context_state, _ = tf.contrib.seq2seq.dynamic_decode(\n","                    my_decoder,\n","                    maximum_iterations=maximum_iterations,\n","                    output_time_major=False,\n","                    impute_finished=False,\n","                    swap_memory=False,\n","                    scope=decoder_scope)\n","\n","                if self.beam_width > 0:\n","                    logits = tf.no_op()\n","                    sample_id = outputs.predicted_ids\n","                else:\n","                    logits = outputs.rnn_output\n","                    sample_id = outputs.sample_id\n","\n","        return logits, sample_id, final_context_state\n","\n","    def build_decoder_cell(self, encoder_outputs, encoder_state,\n","                           sequence_lengths_1):\n","        \"\"\"Builds the attention decoder cell. If mode is inference performs tiling\n","           Passes last encoder state.\n","        \"\"\"\n","\n","        memory = encoder_outputs\n","\n","        if self.mode == 'INFER' and self.beam_width > 0:\n","            memory = tf.contrib.seq2seq.tile_batch(memory,\n","                                                   multiplier=self.beam_width)\n","            encoder_state = tf.contrib.seq2seq.tile_batch(encoder_state,\n","                                                          multiplier=self.beam_width)\n","            sequence_lengths_1 = tf.contrib.seq2seq.tile_batch(sequence_lengths_1,\n","                                                               multiplier=self.beam_width)\n","            batch_size = self.batch_size * self.beam_width\n","\n","        else:\n","            batch_size = self.batch_size\n","\n","        # MY APPROACH\n","        if self.num_layers_decoder is not None:\n","            lstm_cell = tf.nn.rnn_cell.MultiRNNCell(\n","                [self.make_rnn_cell(self.rnn_size_decoder, self.keep_probability) for _ in\n","                 range(self.num_layers_decoder)])\n","\n","        else:\n","            lstm_cell = self.make_rnn_cell(self.rnn_size_decoder, self.keep_probability)\n","\n","        # attention cell\n","        cell = self.make_attention_cell(lstm_cell,\n","                                        self.rnn_size_decoder,\n","                                        memory,\n","                                        sequence_lengths_1)\n","\n","        decoder_initial_state = cell.zero_state(batch_size, tf.float32).clone(cell_state=encoder_state)\n","\n","        return cell, decoder_initial_state\n","\n","\n","    def compute_loss(self, logits):\n","        \"\"\"Compute the loss during optimization.\"\"\"\n","        target_output = self.ids_2\n","        max_time = self.maximum_iterations\n","\n","        target_weights = tf.sequence_mask(self.sequence_lengths_2,\n","                                          max_time,\n","                                          dtype=tf.float32,\n","                                          name='mask')\n","\n","        loss = tf.contrib.seq2seq.sequence_loss(logits=logits,\n","                                                targets=target_output,\n","                                                weights=target_weights,\n","                                                average_across_timesteps=True,\n","                                                average_across_batch=True, )\n","        return loss\n","\n","\n","    def train(self,\n","              inputs,\n","              targets,\n","              restore_path=None,\n","              validation_inputs=None,\n","              validation_targets=None):\n","        \"\"\"Performs the training process. Runs training step in every epoch.\n","           Shuffles input data before every epoch.\n","           Optionally: - add tensorboard summaries.\n","                       - restoring previous model and retraining on top.\n","                       - evaluation step.\n","        \"\"\"\n","        assert len(inputs) == len(targets)\n","\n","        if self.summary_dir is not None:\n","            self.add_summary()\n","\n","        self.initialize_session()\n","        if restore_path is not None:\n","            self.restore_session(restore_path)\n","\n","        best_score = np.inf\n","        nepoch_no_imprv = 0\n","\n","        inputs = np.array(inputs)\n","        targets = np.array(targets)\n","\n","        for epoch in range(self.epochs + 1):\n","            print('-------------------- Epoch {} of {} --------------------'.format(epoch,\n","                                                                                    self.epochs))\n","\n","            # shuffle the input data before every epoch.\n","            shuffle_indices = np.random.permutation(len(inputs))\n","            inputs = inputs[shuffle_indices]\n","            targets = targets[shuffle_indices]\n","\n","            # run training epoch\n","            score = self.run_epoch(inputs, targets, epoch)\n","\n","            # evaluate model\n","            if validation_inputs is not None and validation_targets is not None:\n","                self.run_evaluate(validation_inputs, validation_targets, epoch)\n","\n","\n","            if score <= best_score:\n","                nepoch_no_imprv = 0\n","                if not os.path.exists(self.save_path):\n","                    os.makedirs(self.save_path)\n","                self.saver.save(self.sess, self.save_path)\n","                best_score = score\n","                print(\"--- new best score ---\\n\\n\")\n","            else:\n","                # warm up epochs for the model\n","                if epoch > 10:\n","                    nepoch_no_imprv += 1\n","                # early stopping\n","                if nepoch_no_imprv >= 5:\n","                    print(\"- early stopping {} epochs without improvement\".format(nepoch_no_imprv))\n","                    break\n","\n","    def infer(self, inputs, restore_path, targets=None):\n","        \"\"\"Runs inference process. No training takes place.\n","           Returns the predicted ids for every sentence.\n","        \"\"\"\n","        self.initialize_session()\n","        self.restore_session(restore_path)\n","\n","        prediction_ids = []\n","        if targets is not None:\n","            feed, _, sequence_lengths_2 = self.get_feed_dict(inputs, trgts=targets)\n","        else:\n","            feed, _ = self.get_feed_dict(inputs)\n","\n","        infer_logits, s_ids = self.sess.run([self.infer_logits, self.sample_words], feed_dict=feed)\n","        prediction_ids.append(s_ids)\n","\n","        # for (inps, trgts) in summarizer_model_utils.minibatches(inputs, targets, self.batch_size):\n","        #     feed, _, sequence_lengths= self.get_feed_dict(inps, trgts=trgts)\n","        #     infer_logits, s_ids = self.sess.run([self.infer_logits, self.sample_words], feed_dict = feed)\n","        #     prediction_ids.append(s_ids)\n","\n","        return prediction_ids\n","\n","    def run_epoch(self, inputs, targets, epoch):\n","        \"\"\"Runs a single epoch.\n","           Returns the average loss value on the epoch.\"\"\"\n","        batch_size = self.batch_size\n","        nbatches = (len(inputs) + batch_size - 1) // batch_size\n","        losses = []\n","\n","        for i, (inps, trgts) in enumerate(minibatches(inputs,\n","                                                                             targets,\n","                                                                             batch_size)):\n","            if inps is not None and trgts is not None:\n","                fd, sl, s2 = self.get_feed_dict(inps,\n","                                                trgts=trgts)\n","\n","                if i % 10 == 0 and self.summary_dir is not None:\n","                    _, train_loss, training_summ = self.sess.run([self.train_op,\n","                                                                  self.train_loss,\n","                                                                  self.training_summary],\n","                                                                 feed_dict=fd)\n","                    self.training_writer.add_summary(training_summ, epoch*nbatches + i)\n","\n","                else:\n","                    _, train_loss = self.sess.run([self.train_op, self.train_loss],\n","                                                  feed_dict=fd)\n","\n","                if i % 2 == 0 or i == (nbatches - 1):\n","                    print('Iteration: {} of {}\\ttrain_loss: {:.4f}'.format(i, nbatches - 1, train_loss))\n","                losses.append(train_loss)\n","\n","            else:\n","                print('Minibatch empty.')\n","                continue\n","\n","        avg_loss = self.sess.run(tf.reduce_mean(losses))\n","        print('Average Score for this Epoch: {}'.format(avg_loss))\n","\n","        return avg_loss\n","\n","    def run_evaluate(self, inputs, targets, epoch):\n","        \"\"\"Runs evaluation on validation inputs and targets.\n","        Optionally: - writes summary to Tensorboard.\n","        \"\"\"\n","        if self.summary_dir is not None:\n","            eval_losses = []\n","            for inps, trgts in minibatches(inputs, targets, self.batch_size):\n","                fd, sl, s2 = self.get_feed_dict(inps, trgts)\n","                eval_loss = self.sess.run([self.eval_loss], feed_dict=fd)\n","                eval_losses.append(eval_loss)\n","\n","            avg_eval_loss = self.sess.run(tf.reduce_mean(eval_losses))\n","\n","            print('Eval_loss: {}\\n'.format(avg_eval_loss))\n","            eval_summ = self.sess.run([self.eval_summary], feed_dict=fd)\n","            self.eval_writer.add_summary(eval_summ, epoch)\n","\n","        else:\n","            eval_losses = []\n","            for inps, trgts in minibatches(inputs, targets, self.batch_size):\n","                fd, sl, s2 = self.get_feed_dict(inps, trgts)\n","                eval_loss = self.sess.run([self.eval_loss], feed_dict=fd)\n","                eval_losses.append(eval_loss)\n","\n","            avg_eval_loss = self.sess.run(tf.reduce_mean(eval_losses))\n","\n","            print('Eval_loss: {}\\n'.format(avg_eval_loss))\n","\n","\n","\n","    def get_feed_dict(self, inps, trgts=None):\n","        \"\"\"Creates the feed_dict that is fed into training or inference network.\n","           Pads inputs and targets.\n","           Returns feed_dict and sequence_length(s) depending on training mode.\n","        \"\"\"\n","        if self.mode != 'INFER':\n","            inp_ids, sequence_lengths_1 = pad_sequences(inps,\n","                                                                               self.word2ind[self.pad],\n","                                                                               tail=False)\n","\n","            feed = {\n","                self.ids_1: inp_ids,\n","                self.sequence_lengths_1: sequence_lengths_1\n","            }\n","\n","            if trgts is not None:\n","                trgt_ids, sequence_lengths_2 = pad_sequences(trgts,\n","                                                                                    self.word2ind[self.pad],\n","                                                                                    tail=True)\n","                feed[self.ids_2] = trgt_ids\n","                feed[self.sequence_lengths_2] = sequence_lengths_2\n","\n","                return feed, sequence_lengths_1, sequence_lengths_2\n","\n","        else:\n","\n","            inp_ids, sequence_lengths_1 = pad_sequences(inps,\n","                                                                               self.word2ind[self.pad],\n","                                                                               tail=False)\n","\n","            feed = {\n","                self.ids_1: inp_ids,\n","                self.sequence_lengths_1: sequence_lengths_1\n","            }\n","\n","            if trgts is not None:\n","                trgt_ids, sequence_lengths_2 = pad_sequences(trgts,\n","                                                                                    self.word2ind[self.pad],\n","                                                                                    tail=True)\n","\n","                feed[self.sequence_lengths_2] = sequence_lengths_2\n","\n","                return feed, sequence_lengths_1, sequence_lengths_2\n","            else:\n","                return feed, sequence_lengths_1\n","\n","    def initialize_session(self):\n","        self.sess = tf.Session()\n","        self.sess.run(tf.global_variables_initializer())\n","\n","    def restore_session(self, restore_path):\n","        self.saver.restore(self.sess, restore_path)\n","        print('Done.')\n","\n","    def add_summary(self):\n","        \"\"\"Summaries for Tensorboard.\"\"\"\n","        self.training_summary = tf.summary.scalar('training_loss', self.train_loss)\n","        self.eval_summary = tf.summary.scalar('evaluation_loss', self.eval_loss)\n","        self.training_writer = tf.summary.FileWriter(self.summary_dir,\n","                                                     tf.get_default_graph())\n","        self.eval_writer = tf.summary.FileWriter(self.summary_dir)\n","\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: rouge in /usr/local/lib/python3.6/dist-packages (0.3.2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"caLhlSiUXEf8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"54d819bf-9cb5-4c4d-9216-5693f9cab52a","executionInfo":{"status":"ok","timestamp":1556960863388,"user_tz":-330,"elapsed":850,"user":{"displayName":"arpit.jain arpit.jain","photoUrl":"https://lh5.googleusercontent.com/-cBrzJn4bZ70/AAAAAAAAAAI/AAAAAAAAA4k/GAn2TH00IbM/s64/photo.jpg","userId":"08694739481247522869"}}},"source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","from collections import Counter"],"execution_count":2,"outputs":[{"output_type":"stream","text":["WARNING: Logging before flag parsing goes to stderr.\n","W0504 09:07:51.519484 140572899837824 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"LMvpSQcSXuKJ","colab_type":"code","outputId":"e4dd99e9-8ae0-49e1-f085-02d75eddd517","colab":{"base_uri":"https://localhost:8080/","height":493},"executionInfo":{"status":"ok","timestamp":1556960890798,"user_tz":-330,"elapsed":25498,"user":{"displayName":"arpit.jain arpit.jain","photoUrl":"https://lh5.googleusercontent.com/-cBrzJn4bZ70/AAAAAAAAAAI/AAAAAAAAA4k/GAn2TH00IbM/s64/photo.jpg","userId":"08694739481247522869"}}},"source":["!pip install -U -q PyDrive\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","# Authenticate and create the PyDrive client.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","link = 'https://drive.google.com/open?id=1PndmcFsSpFcD7xtut1Vxg5rQMjpOiVEZ' # The shareable link\n","fluff, id = link.split('=')\n","downloaded = drive.CreateFile({'id':id}) \n","downloaded.GetContentFile('articles1.csv') \n","data1 = pd.read_csv('articles1.csv', encoding='utf-8')\n","link = 'https://drive.google.com/open?id=1v-dugtDcy7jpzgnhMGLzZt5G8VGuvbDf' # The shareable link\n","fluff, id = link.split('=')\n","downloaded = drive.CreateFile({'id':id}) \n","downloaded.GetContentFile('articles2.csv') \n","data2 = pd.read_csv('articles2.csv', encoding='utf-8')\n","link = 'https://drive.google.com/open?id=1vUTInK2FChtoqGDpb1EiHMPsvbD9w6ki' # The shareable link\n","fluff, id = link.split('=')\n","downloaded = drive.CreateFile({'id':id}) \n","downloaded.GetContentFile('articles3.csv') \n","data3 = pd.read_csv('articles3.csv', encoding='utf-8')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["W0504 09:08:02.260640 140572899837824 __init__.py:44] file_cache is unavailable when using oauth2client >= 4.0.0\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 36, in autodetect\n","    from google.appengine.api import memcache\n","ModuleNotFoundError: No module named 'google.appengine'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 33, in <module>\n","    from oauth2client.contrib.locked_file import LockedFile\n","ModuleNotFoundError: No module named 'oauth2client.contrib.locked_file'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 37, in <module>\n","    from oauth2client.locked_file import LockedFile\n","ModuleNotFoundError: No module named 'oauth2client.locked_file'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 41, in autodetect\n","    from . import file_cache\n","  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 41, in <module>\n","    'file_cache is unavailable when using oauth2client >= 4.0.0')\n","ImportError: file_cache is unavailable when using oauth2client >= 4.0.0\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"X3-wvv50x1Rk","colab_type":"code","outputId":"96c2aa83-58d7-4633-c0ac-9bbf276c8d22","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1556960894313,"user_tz":-330,"elapsed":1082,"user":{"displayName":"arpit.jain arpit.jain","photoUrl":"https://lh5.googleusercontent.com/-cBrzJn4bZ70/AAAAAAAAAAI/AAAAAAAAA4k/GAn2TH00IbM/s64/photo.jpg","userId":"08694739481247522869"}}},"source":["data = pd.concat([data1, data2, data3])\n","print(Counter(data.publication))\n","data.dropna(subset=['title'], inplace = True)\n","# the columns. \n","data.rename(index = str, columns = {'title':'Summary', 'content':'Text'}, inplace = True)\n","data = data[['Summary', 'Text']]\n"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Counter({'Breitbart': 23781, 'New York Post': 17493, 'NPR': 11992, 'CNN': 11488, 'Washington Post': 11114, 'Reuters': 10710, 'Guardian': 8681, 'New York Times': 7803, 'Atlantic': 7179, 'Business Insider': 6757, 'National Review': 6203, 'Talking Points Memo': 5214, 'Vox': 4947, 'Buzzfeed News': 4854, 'Fox News': 4354})\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-kg0APEs4bGl","colab_type":"code","outputId":"31141e57-5a4a-4a0e-9214-f8ddd81dc4c7","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1556960903286,"user_tz":-330,"elapsed":6307,"user":{"displayName":"arpit.jain arpit.jain","photoUrl":"https://lh5.googleusercontent.com/-cBrzJn4bZ70/AAAAAAAAAAI/AAAAAAAAA4k/GAn2TH00IbM/s64/photo.jpg","userId":"08694739481247522869"}}},"source":["import nltk\n","nltk.download('punkt')\n","# again we will not use all of the examples, but only pick some. \n","len_summaries = [len(summary) for i, summary in enumerate(data.Summary)]\n","len_texts = [len(text) for text in data.Text]\n","len_summaries_counted = Counter(len_summaries).most_common()\n","len_texts_counted = Counter(len_texts).most_common()\n","texts_unprocessed = []\n","summaries_unprocessed = []\n","cc=0\n","indices = [ind for ind, text in enumerate(data.Text) if 50 < len(text) < 200]\n","for i in indices:\n","    texts_unprocessed.insert(cc,data.Text[i])\n","    summaries_unprocessed.insert(cc,data.Summary[i])\n","    cc = cc+1\n","# articles from nyt and breitbart seem to have those endings, therefore\n","# we will remove those, as that is not relevant. \n","to_remove = ['- The New York Times', '- Breitbart']\n","\n","summaries_unprocessed_clean = []\n","texts_unprocessed_clean = []\n","\n","removed = 0\n","append = True\n","for sentence in summaries_unprocessed:\n","    append = True\n","    for r in to_remove:\n","        if sentence.endswith(r):\n","            sentence = sentence.replace(r, '.')\n","            summaries_unprocessed_clean.append(sentence.replace(r, '.'))\n","            removed+=1\n","            append = False\n","            break\n","            \n","    if append:\n","        summaries_unprocessed_clean.append(sentence)\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"t5pSBit54ubW","colab_type":"code","outputId":"15e54aab-5cc9-4193-a11f-b17e972806be","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1556960906175,"user_tz":-330,"elapsed":1962,"user":{"displayName":"arpit.jain arpit.jain","photoUrl":"https://lh5.googleusercontent.com/-cBrzJn4bZ70/AAAAAAAAAAI/AAAAAAAAA4k/GAn2TH00IbM/s64/photo.jpg","userId":"08694739481247522869"}}},"source":["processed_texts, processed_summaries, words_counted = preprocess_texts_and_summaries(texts_unprocessed, summaries_unprocessed_clean, keep_most=False)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Processing Time:  0.46903491020202637\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ExwBSyua5XkL","colab_type":"code","colab":{}},"source":["processed_texts_clean = []\n","processed_summaries_clean = []\n","\n","for t, s in zip(processed_texts, processed_summaries):\n","    if t != [] and s != []:\n","        processed_texts_clean.append(t)\n","        processed_summaries_clean.append(s)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2PIRP7Cr5dHg","colab_type":"code","outputId":"7f652b4b-cca5-4225-923f-7431c47e3b9d","colab":{"base_uri":"https://localhost:8080/","height":782},"executionInfo":{"status":"ok","timestamp":1556960910991,"user_tz":-330,"elapsed":941,"user":{"displayName":"arpit.jain arpit.jain","photoUrl":"https://lh5.googleusercontent.com/-cBrzJn4bZ70/AAAAAAAAAAI/AAAAAAAAA4k/GAn2TH00IbM/s64/photo.jpg","userId":"08694739481247522869"}}},"source":["specials = [\"<EOS>\", \"<SOS>\",\"<PAD>\",\"<UNK>\"]\n","word2ind, ind2word,  missing_words = create_word_inds_dicts(words_counted, specials = specials, min_occurences = 1)\n","print(len(word2ind), len(ind2word), len(missing_words))\n","missing_words"],"execution_count":8,"outputs":[{"output_type":"stream","text":["5195 5195 44\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["['ky',\n"," '56',\n"," 'st',\n"," '51',\n"," '90',\n"," '58',\n"," '65',\n"," '73',\n"," '53',\n"," '60',\n"," 'ta',\n"," '3d',\n"," 'ol',\n"," '09',\n"," '54',\n"," 'lt',\n"," 'xi',\n"," 'ag',\n"," '77',\n"," 'g7',\n"," 'g6',\n"," '06',\n"," '49',\n"," '96',\n"," 'rm',\n"," 'id',\n"," '2k',\n"," 'im',\n"," 'la',\n"," 'qa',\n"," 'ld',\n"," 'mi',\n"," '3m',\n"," 'ck',\n"," '66',\n"," 'ai',\n"," 'f1',\n"," '33',\n"," 'el',\n"," 'iv',\n"," '91',\n"," '9b',\n"," 'op',\n"," 'cw']"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"R3r_IpiT5jcV","colab_type":"code","outputId":"49c64b73-ab53-4b0d-8c40-dc4e210d3991","colab":{"base_uri":"https://localhost:8080/","height":173},"executionInfo":{"status":"ok","timestamp":1556960917013,"user_tz":-330,"elapsed":4660,"user":{"displayName":"arpit.jain arpit.jain","photoUrl":"https://lh5.googleusercontent.com/-cBrzJn4bZ70/AAAAAAAAAAI/AAAAAAAAA4k/GAn2TH00IbM/s64/photo.jpg","userId":"08694739481247522869"}}},"source":["embed = hub.Module(\"https://tfhub.dev/google/Wiki-words-250/1\")\n","emb = embed([key for key in word2ind.keys()])\n","\n","with tf.Session() as sess:\n","    sess.run(tf.global_variables_initializer())\n","    sess.run(tf.tables_initializer())\n","    embedding = sess.run(emb)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n"],"name":"stdout"},{"output_type":"stream","text":["W0504 09:08:41.349959 140572899837824 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stdout"},{"output_type":"stream","text":["I0504 09:08:41.438520 140572899837824 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"refpt5995mUm","colab_type":"code","colab":{}},"source":["np.save('./tf_hub_embedding_headlines.npy', embedding)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cd3Q9zVLuko4","colab_type":"code","outputId":"9ae70ecb-e96c-4507-eb5e-a70e4c64a9da","colab":{"base_uri":"https://localhost:8080/","height":71},"executionInfo":{"status":"ok","timestamp":1556960921122,"user_tz":-330,"elapsed":933,"user":{"displayName":"arpit.jain arpit.jain","photoUrl":"https://lh5.googleusercontent.com/-cBrzJn4bZ70/AAAAAAAAAAI/AAAAAAAAA4k/GAn2TH00IbM/s64/photo.jpg","userId":"08694739481247522869"}}},"source":["converted_texts, unknown_words_in_texts = convert_to_inds(processed_texts_clean, word2ind, eos = False)\n","converted_summaries, unknown_words_in_summaries = convert_to_inds(processed_summaries_clean, word2ind, eos = True, sos = True)\n","\n","print(convert_inds_to_text(converted_texts[0], ind2word))\n","print(convert_inds_to_text(converted_summaries[0], ind2word))"],"execution_count":11,"outputs":[{"output_type":"stream","text":["['in', 'major', 'abortion', 'ruling', 'monday', 'the', 'supreme', 'court', 'struck', 'down', 'parts', 'of', 'texas', 'law', 'that', 'would', 'have', 'forced', 'dozens', 'of', 'clinics', 'to', 'close', 'here', 'are', 'reactions', 'from', 'all', 'sides', 'of', 'the', 'issue']\n","['<SOS>', 'reactions', 'to', 'the', 'supreme', 'court', 'ruling', 'on', 'texas', 'abortion', 'law', '<EOS>']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dofR-Ajp5uNr","colab_type":"code","outputId":"50b72edb-6461-40bd-bce5-7c1fa933dc71","colab":{"base_uri":"https://localhost:8080/","height":26217},"executionInfo":{"status":"ok","timestamp":1556964061986,"user_tz":-330,"elapsed":3139427,"user":{"displayName":"arpit.jain arpit.jain","photoUrl":"https://lh5.googleusercontent.com/-cBrzJn4bZ70/AAAAAAAAAAI/AAAAAAAAA4k/GAn2TH00IbM/s64/photo.jpg","userId":"08694739481247522869"}}},"source":["# model hyperparameters\n","num_layers_encoder = 4\n","num_layers_decoder = 4\n","rnn_size_encoder = 300\n","rnn_size_decoder = 300\n","\n","batch_size = 32\n","epochs = 100\n","clip = 5\n","keep_probability = 0.8\n","learning_rate = 0.0005\n","max_lr=0.005\n","learning_rate_decay_steps = 100\n","learning_rate_decay = 0.90\n","\n","\n","pretrained_embeddings_path = './tf_hub_embedding_headlines.npy'\n","summary_dir = os.path.join('./tensorboard/headlines')\n","\n","use_cyclic_lr = True\n","inference_targets=True\n","\n","reset_graph()\n","summarizer = Summarizer(word2ind,\n","                                   ind2word,\n","                                   save_path='./models/headlines/my_model',\n","                                   mode='TRAIN',\n","                                   num_layers_encoder = num_layers_encoder,\n","                                   num_layers_decoder = num_layers_decoder,\n","                                   rnn_size_encoder = rnn_size_encoder,\n","                                   rnn_size_decoder = rnn_size_decoder,\n","                                   batch_size = batch_size,\n","                                   clip = clip,\n","                                   keep_probability = keep_probability,\n","                                   learning_rate = learning_rate,\n","                                   max_lr=max_lr,\n","                                   learning_rate_decay_steps = learning_rate_decay_steps,\n","                                   learning_rate_decay = learning_rate_decay,\n","                                   epochs = epochs,\n","                                   pretrained_embeddings_path = pretrained_embeddings_path,\n","                                   use_cyclic_lr = use_cyclic_lr,)\n","#                                    summary_dir = summary_dir)           \n","\n","summarizer.build_graph()\n","summarizer.train(converted_texts, converted_summaries)\n","\n"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Loaded pretrained embeddings.\n","WARNING:tensorflow:From <ipython-input-1-9b28d95ea18a>:531: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n"],"name":"stdout"},{"output_type":"stream","text":["W0504 09:08:51.625293 140572899837824 deprecation.py:323] From <ipython-input-1-9b28d95ea18a>:531: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-1-9b28d95ea18a>:628: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n"],"name":"stdout"},{"output_type":"stream","text":["W0504 09:08:51.639512 140572899837824 deprecation.py:323] From <ipython-input-1-9b28d95ea18a>:628: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py:443: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n"],"name":"stdout"},{"output_type":"stream","text":["W0504 09:08:51.641821 140572899837824 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py:443: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py:626: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n"],"name":"stdout"},{"output_type":"stream","text":["W0504 09:08:51.655627 140572899837824 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn.py:626: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:1259: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"],"name":"stdout"},{"output_type":"stream","text":["W0504 09:08:51.739576 140572899837824 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:1259: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From <ipython-input-1-9b28d95ea18a>:757: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n"],"name":"stdout"},{"output_type":"stream","text":["W0504 09:08:52.856210 140572899837824 deprecation.py:323] From <ipython-input-1-9b28d95ea18a>:757: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n"],"name":"stderr"},{"output_type":"stream","text":["\n","WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/seq2seq/python/ops/helper.py:311: Bernoulli.__init__ (from tensorflow.python.ops.distributions.bernoulli) is deprecated and will be removed after 2019-01-01.\n","Instructions for updating:\n","The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"],"name":"stdout"},{"output_type":"stream","text":["W0504 09:08:54.282630 140572899837824 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/seq2seq/python/ops/helper.py:311: Bernoulli.__init__ (from tensorflow.python.ops.distributions.bernoulli) is deprecated and will be removed after 2019-01-01.\n","Instructions for updating:\n","The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/distributions/bernoulli.py:97: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n","Instructions for updating:\n","The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"],"name":"stdout"},{"output_type":"stream","text":["W0504 09:08:54.295465 140572899837824 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/distributions/bernoulli.py:97: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n","Instructions for updating:\n","The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/seq2seq/python/ops/helper.py:314: Categorical.__init__ (from tensorflow.python.ops.distributions.categorical) is deprecated and will be removed after 2019-01-01.\n","Instructions for updating:\n","The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"],"name":"stdout"},{"output_type":"stream","text":["W0504 09:08:54.318545 140572899837824 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/seq2seq/python/ops/helper.py:314: Categorical.__init__ (from tensorflow.python.ops.distributions.categorical) is deprecated and will be removed after 2019-01-01.\n","Instructions for updating:\n","The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/distributions/categorical.py:278: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.random.categorical instead.\n"],"name":"stdout"},{"output_type":"stream","text":["W0504 09:08:54.327749 140572899837824 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/distributions/categorical.py:278: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.random.categorical instead.\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"],"name":"stderr"},{"output_type":"stream","text":["Graph built.\n","-------------------- Epoch 0 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 8.5557\n","Iteration: 2 of 27\ttrain_loss: 8.5500\n","Iteration: 4 of 27\ttrain_loss: 8.5352\n","Iteration: 6 of 27\ttrain_loss: 8.4361\n","Iteration: 8 of 27\ttrain_loss: 8.1890\n","Iteration: 10 of 27\ttrain_loss: 7.8021\n","Iteration: 12 of 27\ttrain_loss: 7.3826\n","Iteration: 14 of 27\ttrain_loss: 7.0354\n","Iteration: 16 of 27\ttrain_loss: 6.6720\n","Iteration: 18 of 27\ttrain_loss: 6.7883\n","Iteration: 20 of 27\ttrain_loss: 6.7430\n","Iteration: 22 of 27\ttrain_loss: 6.6815\n","Iteration: 24 of 27\ttrain_loss: 7.1834\n","Iteration: 26 of 27\ttrain_loss: 6.7161\n","Iteration: 27 of 27\ttrain_loss: 6.8887\n","Average Score for this Epoch: 7.5029144287109375\n","--- new best score ---\n","\n","\n","-------------------- Epoch 1 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 6.1087\n","Iteration: 2 of 27\ttrain_loss: 6.3086\n","Iteration: 4 of 27\ttrain_loss: 6.4722\n","Iteration: 6 of 27\ttrain_loss: 6.5193\n","Iteration: 8 of 27\ttrain_loss: 6.1649\n","Iteration: 10 of 27\ttrain_loss: 6.2703\n","Iteration: 12 of 27\ttrain_loss: 6.3520\n","Iteration: 14 of 27\ttrain_loss: 6.3307\n","Iteration: 16 of 27\ttrain_loss: 6.2895\n","Iteration: 18 of 27\ttrain_loss: 6.1376\n","Iteration: 20 of 27\ttrain_loss: 6.6112\n","Iteration: 22 of 27\ttrain_loss: 6.4488\n","Iteration: 24 of 27\ttrain_loss: 6.1948\n","Iteration: 26 of 27\ttrain_loss: 6.5349\n","Iteration: 27 of 27\ttrain_loss: 6.2298\n","Average Score for this Epoch: 6.357646465301514\n","--- new best score ---\n","\n","\n","-------------------- Epoch 2 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 6.2107\n","Iteration: 2 of 27\ttrain_loss: 5.9846\n","Iteration: 4 of 27\ttrain_loss: 6.0350\n","Iteration: 6 of 27\ttrain_loss: 6.1516\n","Iteration: 8 of 27\ttrain_loss: 5.9528\n","Iteration: 10 of 27\ttrain_loss: 6.0335\n","Iteration: 12 of 27\ttrain_loss: 6.2519\n","Iteration: 14 of 27\ttrain_loss: 6.1860\n","Iteration: 16 of 27\ttrain_loss: 6.2562\n","Iteration: 18 of 27\ttrain_loss: 6.2590\n","Iteration: 20 of 27\ttrain_loss: 6.5262\n","Iteration: 22 of 27\ttrain_loss: 6.3787\n","Iteration: 24 of 27\ttrain_loss: 6.2272\n","Iteration: 26 of 27\ttrain_loss: 6.0906\n","Iteration: 27 of 27\ttrain_loss: 6.4029\n","Average Score for this Epoch: 6.185648441314697\n","--- new best score ---\n","\n","\n","-------------------- Epoch 3 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 6.1762\n","Iteration: 2 of 27\ttrain_loss: 6.1136\n","Iteration: 4 of 27\ttrain_loss: 5.9337\n","Iteration: 6 of 27\ttrain_loss: 5.8120\n","Iteration: 8 of 27\ttrain_loss: 6.2347\n","Iteration: 10 of 27\ttrain_loss: 6.3480\n","Iteration: 12 of 27\ttrain_loss: 6.1649\n","Iteration: 14 of 27\ttrain_loss: 6.1827\n","Iteration: 16 of 27\ttrain_loss: 6.2042\n","Iteration: 18 of 27\ttrain_loss: 6.2821\n","Iteration: 20 of 27\ttrain_loss: 6.1064\n","Iteration: 22 of 27\ttrain_loss: 6.2435\n","Iteration: 24 of 27\ttrain_loss: 6.1264\n","Iteration: 26 of 27\ttrain_loss: 6.0889\n","Iteration: 27 of 27\ttrain_loss: 6.3064\n","Average Score for this Epoch: 6.139622211456299\n","--- new best score ---\n","\n","\n","-------------------- Epoch 4 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 5.8900\n","Iteration: 2 of 27\ttrain_loss: 5.7715\n","Iteration: 4 of 27\ttrain_loss: 5.9754\n","Iteration: 6 of 27\ttrain_loss: 5.9443\n","Iteration: 8 of 27\ttrain_loss: 5.8661\n","Iteration: 10 of 27\ttrain_loss: 5.9172\n","Iteration: 12 of 27\ttrain_loss: 6.1826\n","Iteration: 14 of 27\ttrain_loss: 5.9801\n","Iteration: 16 of 27\ttrain_loss: 6.0374\n","Iteration: 18 of 27\ttrain_loss: 5.9734\n","Iteration: 20 of 27\ttrain_loss: 6.0405\n","Iteration: 22 of 27\ttrain_loss: 6.1315\n","Iteration: 24 of 27\ttrain_loss: 5.7294\n","Iteration: 26 of 27\ttrain_loss: 5.8733\n","Iteration: 27 of 27\ttrain_loss: 5.9977\n","Average Score for this Epoch: 5.9478278160095215\n","--- new best score ---\n","\n","\n","-------------------- Epoch 5 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 5.6463\n","Iteration: 2 of 27\ttrain_loss: 5.5453\n","Iteration: 4 of 27\ttrain_loss: 5.6548\n","Iteration: 6 of 27\ttrain_loss: 5.7251\n","Iteration: 8 of 27\ttrain_loss: 5.7197\n","Iteration: 10 of 27\ttrain_loss: 5.5525\n","Iteration: 12 of 27\ttrain_loss: 5.8802\n","Iteration: 14 of 27\ttrain_loss: 5.7962\n","Iteration: 16 of 27\ttrain_loss: 5.6843\n","Iteration: 18 of 27\ttrain_loss: 5.8148\n","Iteration: 20 of 27\ttrain_loss: 6.0302\n","Iteration: 22 of 27\ttrain_loss: 5.7156\n","Iteration: 24 of 27\ttrain_loss: 5.8515\n","Iteration: 26 of 27\ttrain_loss: 6.0880\n","Iteration: 27 of 27\ttrain_loss: 5.6084\n","Average Score for this Epoch: 5.777596473693848\n","--- new best score ---\n","\n","\n","-------------------- Epoch 6 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 5.7894\n","Iteration: 2 of 27\ttrain_loss: 5.6888\n","Iteration: 4 of 27\ttrain_loss: 5.6581\n","Iteration: 6 of 27\ttrain_loss: 5.3846\n","Iteration: 8 of 27\ttrain_loss: 5.8873\n","Iteration: 10 of 27\ttrain_loss: 5.6061\n","Iteration: 12 of 27\ttrain_loss: 5.8179\n","Iteration: 14 of 27\ttrain_loss: 5.5294\n","Iteration: 16 of 27\ttrain_loss: 5.7437\n","Iteration: 18 of 27\ttrain_loss: 5.3749\n","Iteration: 20 of 27\ttrain_loss: 5.6347\n","Iteration: 22 of 27\ttrain_loss: 5.7231\n","Iteration: 24 of 27\ttrain_loss: 5.7983\n","Iteration: 26 of 27\ttrain_loss: 5.7130\n","Iteration: 27 of 27\ttrain_loss: 5.6664\n","Average Score for this Epoch: 5.652579307556152\n","--- new best score ---\n","\n","\n","-------------------- Epoch 7 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 5.5825\n","Iteration: 2 of 27\ttrain_loss: 5.6128\n","Iteration: 4 of 27\ttrain_loss: 5.4904\n","Iteration: 6 of 27\ttrain_loss: 5.5410\n","Iteration: 8 of 27\ttrain_loss: 5.6522\n","Iteration: 10 of 27\ttrain_loss: 5.5145\n","Iteration: 12 of 27\ttrain_loss: 5.4749\n","Iteration: 14 of 27\ttrain_loss: 5.3659\n","Iteration: 16 of 27\ttrain_loss: 5.7491\n","Iteration: 18 of 27\ttrain_loss: 5.4343\n","Iteration: 20 of 27\ttrain_loss: 5.8413\n","Iteration: 22 of 27\ttrain_loss: 5.7857\n","Iteration: 24 of 27\ttrain_loss: 5.6802\n","Iteration: 26 of 27\ttrain_loss: 5.3638\n","Iteration: 27 of 27\ttrain_loss: 5.5720\n","Average Score for this Epoch: 5.583283424377441\n","--- new best score ---\n","\n","\n","-------------------- Epoch 8 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 5.7519\n","Iteration: 2 of 27\ttrain_loss: 5.6825\n","Iteration: 4 of 27\ttrain_loss: 5.4997\n","Iteration: 6 of 27\ttrain_loss: 5.6239\n","Iteration: 8 of 27\ttrain_loss: 5.5531\n","Iteration: 10 of 27\ttrain_loss: 5.5449\n","Iteration: 12 of 27\ttrain_loss: 5.4997\n","Iteration: 14 of 27\ttrain_loss: 5.7396\n","Iteration: 16 of 27\ttrain_loss: 5.6133\n","Iteration: 18 of 27\ttrain_loss: 5.8973\n","Iteration: 20 of 27\ttrain_loss: 5.6299\n","Iteration: 22 of 27\ttrain_loss: 5.8284\n","Iteration: 24 of 27\ttrain_loss: 5.7061\n","Iteration: 26 of 27\ttrain_loss: 6.0094\n","Iteration: 27 of 27\ttrain_loss: 5.7402\n","Average Score for this Epoch: 5.605022430419922\n","-------------------- Epoch 9 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 5.4469\n","Iteration: 2 of 27\ttrain_loss: 5.4750\n","Iteration: 4 of 27\ttrain_loss: 5.3888\n","Iteration: 6 of 27\ttrain_loss: 5.4843\n","Iteration: 8 of 27\ttrain_loss: 5.4972\n","Iteration: 10 of 27\ttrain_loss: 5.4956\n","Iteration: 12 of 27\ttrain_loss: 5.6301\n","Iteration: 14 of 27\ttrain_loss: 5.5547\n","Iteration: 16 of 27\ttrain_loss: 5.5787\n","Iteration: 18 of 27\ttrain_loss: 5.5604\n","Iteration: 20 of 27\ttrain_loss: 5.7405\n","Iteration: 22 of 27\ttrain_loss: 5.6584\n","Iteration: 24 of 27\ttrain_loss: 5.7873\n","Iteration: 26 of 27\ttrain_loss: 5.7440\n","Iteration: 27 of 27\ttrain_loss: 5.4826\n","Average Score for this Epoch: 5.598270416259766\n","-------------------- Epoch 10 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 5.4002\n","Iteration: 2 of 27\ttrain_loss: 5.4465\n","Iteration: 4 of 27\ttrain_loss: 5.4344\n","Iteration: 6 of 27\ttrain_loss: 5.3965\n","Iteration: 8 of 27\ttrain_loss: 5.5908\n","Iteration: 10 of 27\ttrain_loss: 5.4465\n","Iteration: 12 of 27\ttrain_loss: 5.6642\n","Iteration: 14 of 27\ttrain_loss: 5.6504\n","Iteration: 16 of 27\ttrain_loss: 5.7157\n","Iteration: 18 of 27\ttrain_loss: 5.4493\n","Iteration: 20 of 27\ttrain_loss: 5.7710\n","Iteration: 22 of 27\ttrain_loss: 5.6846\n","Iteration: 24 of 27\ttrain_loss: 5.7945\n","Iteration: 26 of 27\ttrain_loss: 5.6472\n","Iteration: 27 of 27\ttrain_loss: 5.5532\n","Average Score for this Epoch: 5.572267055511475\n","--- new best score ---\n","\n","\n","-------------------- Epoch 11 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 5.2513\n","Iteration: 2 of 27\ttrain_loss: 5.3771\n","Iteration: 4 of 27\ttrain_loss: 5.4989\n","Iteration: 6 of 27\ttrain_loss: 5.5443\n","Iteration: 8 of 27\ttrain_loss: 5.5039\n","Iteration: 10 of 27\ttrain_loss: 5.3879\n","Iteration: 12 of 27\ttrain_loss: 5.5452\n","Iteration: 14 of 27\ttrain_loss: 5.5154\n","Iteration: 16 of 27\ttrain_loss: 5.5557\n","Iteration: 18 of 27\ttrain_loss: 5.6395\n","Iteration: 20 of 27\ttrain_loss: 5.5335\n","Iteration: 22 of 27\ttrain_loss: 5.2993\n","Iteration: 24 of 27\ttrain_loss: 5.2737\n","Iteration: 26 of 27\ttrain_loss: 5.6753\n","Iteration: 27 of 27\ttrain_loss: 5.2389\n","Average Score for this Epoch: 5.464288234710693\n","--- new best score ---\n","\n","\n","-------------------- Epoch 12 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 5.2460\n","Iteration: 2 of 27\ttrain_loss: 5.2641\n","Iteration: 4 of 27\ttrain_loss: 5.3041\n","Iteration: 6 of 27\ttrain_loss: 5.3281\n","Iteration: 8 of 27\ttrain_loss: 5.1179\n","Iteration: 10 of 27\ttrain_loss: 5.2335\n","Iteration: 12 of 27\ttrain_loss: 5.3772\n","Iteration: 14 of 27\ttrain_loss: 5.3862\n","Iteration: 16 of 27\ttrain_loss: 5.4057\n","Iteration: 18 of 27\ttrain_loss: 5.3802\n","Iteration: 20 of 27\ttrain_loss: 5.3602\n","Iteration: 22 of 27\ttrain_loss: 5.4638\n","Iteration: 24 of 27\ttrain_loss: 5.6433\n","Iteration: 26 of 27\ttrain_loss: 5.2931\n","Iteration: 27 of 27\ttrain_loss: 5.0689\n","Average Score for this Epoch: 5.330607891082764\n","--- new best score ---\n","\n","\n","-------------------- Epoch 13 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 5.2535\n","Iteration: 2 of 27\ttrain_loss: 5.3550\n","Iteration: 4 of 27\ttrain_loss: 5.2078\n","Iteration: 6 of 27\ttrain_loss: 5.0800\n","Iteration: 8 of 27\ttrain_loss: 5.2907\n","Iteration: 10 of 27\ttrain_loss: 5.3042\n","Iteration: 12 of 27\ttrain_loss: 5.4530\n","Iteration: 14 of 27\ttrain_loss: 5.2495\n","Iteration: 16 of 27\ttrain_loss: 5.2162\n","Iteration: 18 of 27\ttrain_loss: 5.2531\n","Iteration: 20 of 27\ttrain_loss: 4.9927\n","Iteration: 22 of 27\ttrain_loss: 5.2818\n","Iteration: 24 of 27\ttrain_loss: 5.2027\n","Iteration: 26 of 27\ttrain_loss: 5.4149\n","Iteration: 27 of 27\ttrain_loss: 5.2071\n","Average Score for this Epoch: 5.234683036804199\n","--- new best score ---\n","\n","\n","-------------------- Epoch 14 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 5.0428\n","Iteration: 2 of 27\ttrain_loss: 5.3335\n","Iteration: 4 of 27\ttrain_loss: 5.2244\n","Iteration: 6 of 27\ttrain_loss: 5.0955\n","Iteration: 8 of 27\ttrain_loss: 5.1933\n","Iteration: 10 of 27\ttrain_loss: 5.0795\n","Iteration: 12 of 27\ttrain_loss: 5.1798\n","Iteration: 14 of 27\ttrain_loss: 4.9787\n","Iteration: 16 of 27\ttrain_loss: 5.3673\n","Iteration: 18 of 27\ttrain_loss: 5.3056\n","Iteration: 20 of 27\ttrain_loss: 5.3334\n","Iteration: 22 of 27\ttrain_loss: 5.3217\n","Iteration: 24 of 27\ttrain_loss: 5.1811\n","Iteration: 26 of 27\ttrain_loss: 5.3636\n","Iteration: 27 of 27\ttrain_loss: 5.0832\n","Average Score for this Epoch: 5.162450313568115\n","--- new best score ---\n","\n","\n","-------------------- Epoch 15 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 5.2468\n","Iteration: 2 of 27\ttrain_loss: 4.9570\n","Iteration: 4 of 27\ttrain_loss: 5.0847\n","Iteration: 6 of 27\ttrain_loss: 5.3091\n","Iteration: 8 of 27\ttrain_loss: 5.2941\n","Iteration: 10 of 27\ttrain_loss: 5.1184\n","Iteration: 12 of 27\ttrain_loss: 5.1885\n","Iteration: 14 of 27\ttrain_loss: 5.3018\n","Iteration: 16 of 27\ttrain_loss: 5.3179\n","Iteration: 18 of 27\ttrain_loss: 5.2274\n","Iteration: 20 of 27\ttrain_loss: 5.1262\n","Iteration: 22 of 27\ttrain_loss: 5.3106\n","Iteration: 24 of 27\ttrain_loss: 5.2955\n","Iteration: 26 of 27\ttrain_loss: 5.1753\n","Iteration: 27 of 27\ttrain_loss: 5.2840\n","Average Score for this Epoch: 5.180657386779785\n","-------------------- Epoch 16 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 5.1008\n","Iteration: 2 of 27\ttrain_loss: 5.1824\n","Iteration: 4 of 27\ttrain_loss: 5.0086\n","Iteration: 6 of 27\ttrain_loss: 5.3805\n","Iteration: 8 of 27\ttrain_loss: 4.9941\n","Iteration: 10 of 27\ttrain_loss: 5.0149\n","Iteration: 12 of 27\ttrain_loss: 5.1170\n","Iteration: 14 of 27\ttrain_loss: 5.1142\n","Iteration: 16 of 27\ttrain_loss: 5.1825\n","Iteration: 18 of 27\ttrain_loss: 5.1021\n","Iteration: 20 of 27\ttrain_loss: 5.1858\n","Iteration: 22 of 27\ttrain_loss: 5.1683\n","Iteration: 24 of 27\ttrain_loss: 5.1993\n","Iteration: 26 of 27\ttrain_loss: 5.2069\n","Iteration: 27 of 27\ttrain_loss: 5.0070\n","Average Score for this Epoch: 5.177541255950928\n","-------------------- Epoch 17 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 5.1033\n","Iteration: 2 of 27\ttrain_loss: 4.9789\n","Iteration: 4 of 27\ttrain_loss: 4.7926\n","Iteration: 6 of 27\ttrain_loss: 5.0330\n","Iteration: 8 of 27\ttrain_loss: 4.9121\n","Iteration: 10 of 27\ttrain_loss: 5.2920\n","Iteration: 12 of 27\ttrain_loss: 5.2588\n","Iteration: 14 of 27\ttrain_loss: 5.3516\n","Iteration: 16 of 27\ttrain_loss: 5.2388\n","Iteration: 18 of 27\ttrain_loss: 5.3968\n","Iteration: 20 of 27\ttrain_loss: 5.2271\n","Iteration: 22 of 27\ttrain_loss: 5.2238\n","Iteration: 24 of 27\ttrain_loss: 5.2367\n","Iteration: 26 of 27\ttrain_loss: 5.3659\n","Iteration: 27 of 27\ttrain_loss: 5.1178\n","Average Score for this Epoch: 5.160886287689209\n","--- new best score ---\n","\n","\n","-------------------- Epoch 18 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 5.1956\n","Iteration: 2 of 27\ttrain_loss: 4.9411\n","Iteration: 4 of 27\ttrain_loss: 5.1680\n","Iteration: 6 of 27\ttrain_loss: 5.0039\n","Iteration: 8 of 27\ttrain_loss: 5.1425\n","Iteration: 10 of 27\ttrain_loss: 4.7731\n","Iteration: 12 of 27\ttrain_loss: 4.8765\n","Iteration: 14 of 27\ttrain_loss: 5.1552\n","Iteration: 16 of 27\ttrain_loss: 5.0566\n","Iteration: 18 of 27\ttrain_loss: 4.9120\n","Iteration: 20 of 27\ttrain_loss: 5.0515\n","Iteration: 22 of 27\ttrain_loss: 5.0627\n","Iteration: 24 of 27\ttrain_loss: 5.3007\n","Iteration: 26 of 27\ttrain_loss: 5.4143\n","Iteration: 27 of 27\ttrain_loss: 5.1092\n","Average Score for this Epoch: 5.0894036293029785\n","--- new best score ---\n","\n","\n","-------------------- Epoch 19 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 4.8864\n","Iteration: 2 of 27\ttrain_loss: 4.9821\n","Iteration: 4 of 27\ttrain_loss: 4.9998\n","Iteration: 6 of 27\ttrain_loss: 4.9185\n","Iteration: 8 of 27\ttrain_loss: 4.8432\n","Iteration: 10 of 27\ttrain_loss: 4.8497\n","Iteration: 12 of 27\ttrain_loss: 4.8944\n","Iteration: 14 of 27\ttrain_loss: 5.1336\n","Iteration: 16 of 27\ttrain_loss: 5.0081\n","Iteration: 18 of 27\ttrain_loss: 5.0573\n","Iteration: 20 of 27\ttrain_loss: 4.9115\n","Iteration: 22 of 27\ttrain_loss: 5.0822\n","Iteration: 24 of 27\ttrain_loss: 5.0113\n","Iteration: 26 of 27\ttrain_loss: 5.0136\n","Iteration: 27 of 27\ttrain_loss: 4.7173\n","Average Score for this Epoch: 4.968012809753418\n","--- new best score ---\n","\n","\n","-------------------- Epoch 20 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 4.9416\n","Iteration: 2 of 27\ttrain_loss: 4.8051\n","Iteration: 4 of 27\ttrain_loss: 4.9110\n","Iteration: 6 of 27\ttrain_loss: 5.0726\n","Iteration: 8 of 27\ttrain_loss: 4.5509\n","Iteration: 10 of 27\ttrain_loss: 4.8215\n","Iteration: 12 of 27\ttrain_loss: 4.9144\n","Iteration: 14 of 27\ttrain_loss: 4.8410\n","Iteration: 16 of 27\ttrain_loss: 4.8317\n","Iteration: 18 of 27\ttrain_loss: 5.0667\n","Iteration: 20 of 27\ttrain_loss: 4.9307\n","Iteration: 22 of 27\ttrain_loss: 4.7081\n","Iteration: 24 of 27\ttrain_loss: 4.9563\n","Iteration: 26 of 27\ttrain_loss: 5.0384\n","Iteration: 27 of 27\ttrain_loss: 4.7870\n","Average Score for this Epoch: 4.864412784576416\n","--- new best score ---\n","\n","\n","-------------------- Epoch 21 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 4.8090\n","Iteration: 2 of 27\ttrain_loss: 4.8238\n","Iteration: 4 of 27\ttrain_loss: 4.7112\n","Iteration: 6 of 27\ttrain_loss: 4.9455\n","Iteration: 8 of 27\ttrain_loss: 4.6355\n","Iteration: 10 of 27\ttrain_loss: 4.8046\n","Iteration: 12 of 27\ttrain_loss: 4.5973\n","Iteration: 14 of 27\ttrain_loss: 4.9228\n","Iteration: 16 of 27\ttrain_loss: 4.8264\n","Iteration: 18 of 27\ttrain_loss: 4.7046\n","Iteration: 20 of 27\ttrain_loss: 4.6837\n","Iteration: 22 of 27\ttrain_loss: 4.8330\n","Iteration: 24 of 27\ttrain_loss: 4.9421\n","Iteration: 26 of 27\ttrain_loss: 4.8300\n","Iteration: 27 of 27\ttrain_loss: 4.7743\n","Average Score for this Epoch: 4.783374786376953\n","--- new best score ---\n","\n","\n","-------------------- Epoch 22 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 4.6037\n","Iteration: 2 of 27\ttrain_loss: 4.6088\n","Iteration: 4 of 27\ttrain_loss: 4.8011\n","Iteration: 6 of 27\ttrain_loss: 4.7350\n","Iteration: 8 of 27\ttrain_loss: 4.6173\n","Iteration: 10 of 27\ttrain_loss: 4.9104\n","Iteration: 12 of 27\ttrain_loss: 4.7742\n","Iteration: 14 of 27\ttrain_loss: 4.7387\n","Iteration: 16 of 27\ttrain_loss: 4.7250\n","Iteration: 18 of 27\ttrain_loss: 4.6361\n","Iteration: 20 of 27\ttrain_loss: 4.7350\n","Iteration: 22 of 27\ttrain_loss: 4.8946\n","Iteration: 24 of 27\ttrain_loss: 5.0857\n","Iteration: 26 of 27\ttrain_loss: 4.9411\n","Iteration: 27 of 27\ttrain_loss: 4.6531\n","Average Score for this Epoch: 4.781906604766846\n","--- new best score ---\n","\n","\n","-------------------- Epoch 23 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 4.6553\n","Iteration: 2 of 27\ttrain_loss: 4.5509\n","Iteration: 4 of 27\ttrain_loss: 4.7802\n","Iteration: 6 of 27\ttrain_loss: 4.5969\n","Iteration: 8 of 27\ttrain_loss: 4.6788\n","Iteration: 10 of 27\ttrain_loss: 4.6996\n","Iteration: 12 of 27\ttrain_loss: 4.9697\n","Iteration: 14 of 27\ttrain_loss: 4.8141\n","Iteration: 16 of 27\ttrain_loss: 5.0180\n","Iteration: 18 of 27\ttrain_loss: 4.9584\n","Iteration: 20 of 27\ttrain_loss: 4.8501\n","Iteration: 22 of 27\ttrain_loss: 4.9359\n","Iteration: 24 of 27\ttrain_loss: 4.8906\n","Iteration: 26 of 27\ttrain_loss: 4.6974\n","Iteration: 27 of 27\ttrain_loss: 4.6196\n","Average Score for this Epoch: 4.786789894104004\n","-------------------- Epoch 24 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 4.5744\n","Iteration: 2 of 27\ttrain_loss: 4.5256\n","Iteration: 4 of 27\ttrain_loss: 4.4202\n","Iteration: 6 of 27\ttrain_loss: 4.5038\n","Iteration: 8 of 27\ttrain_loss: 4.4747\n","Iteration: 10 of 27\ttrain_loss: 4.6847\n","Iteration: 12 of 27\ttrain_loss: 4.9282\n","Iteration: 14 of 27\ttrain_loss: 4.9483\n","Iteration: 16 of 27\ttrain_loss: 4.7580\n","Iteration: 18 of 27\ttrain_loss: 4.8612\n","Iteration: 20 of 27\ttrain_loss: 4.9085\n","Iteration: 22 of 27\ttrain_loss: 5.0344\n","Iteration: 24 of 27\ttrain_loss: 4.9862\n","Iteration: 26 of 27\ttrain_loss: 5.1188\n","Iteration: 27 of 27\ttrain_loss: 4.6264\n","Average Score for this Epoch: 4.794619083404541\n","-------------------- Epoch 25 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 4.6410\n","Iteration: 2 of 27\ttrain_loss: 4.6839\n","Iteration: 4 of 27\ttrain_loss: 4.5762\n","Iteration: 6 of 27\ttrain_loss: 4.5841\n","Iteration: 8 of 27\ttrain_loss: 4.6762\n","Iteration: 10 of 27\ttrain_loss: 4.7096\n","Iteration: 12 of 27\ttrain_loss: 4.6834\n","Iteration: 14 of 27\ttrain_loss: 4.9114\n","Iteration: 16 of 27\ttrain_loss: 4.8686\n","Iteration: 18 of 27\ttrain_loss: 4.6673\n","Iteration: 20 of 27\ttrain_loss: 4.7043\n","Iteration: 22 of 27\ttrain_loss: 5.0601\n","Iteration: 24 of 27\ttrain_loss: 4.5290\n","Iteration: 26 of 27\ttrain_loss: 4.9800\n","Iteration: 27 of 27\ttrain_loss: 4.6692\n","Average Score for this Epoch: 4.737795352935791\n","--- new best score ---\n","\n","\n","-------------------- Epoch 26 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 4.5921\n","Iteration: 2 of 27\ttrain_loss: 4.4946\n","Iteration: 4 of 27\ttrain_loss: 4.4964\n","Iteration: 6 of 27\ttrain_loss: 4.3101\n","Iteration: 8 of 27\ttrain_loss: 4.2846\n","Iteration: 10 of 27\ttrain_loss: 4.6598\n","Iteration: 12 of 27\ttrain_loss: 4.5559\n","Iteration: 14 of 27\ttrain_loss: 4.4672\n","Iteration: 16 of 27\ttrain_loss: 4.9196\n","Iteration: 18 of 27\ttrain_loss: 4.6780\n","Iteration: 20 of 27\ttrain_loss: 4.7008\n","Iteration: 22 of 27\ttrain_loss: 4.7272\n","Iteration: 24 of 27\ttrain_loss: 4.8431\n","Iteration: 26 of 27\ttrain_loss: 4.6522\n","Iteration: 27 of 27\ttrain_loss: 4.5202\n","Average Score for this Epoch: 4.627405643463135\n","--- new best score ---\n","\n","\n","-------------------- Epoch 27 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 4.2805\n","Iteration: 2 of 27\ttrain_loss: 4.5323\n","Iteration: 4 of 27\ttrain_loss: 4.6708\n","Iteration: 6 of 27\ttrain_loss: 4.4501\n","Iteration: 8 of 27\ttrain_loss: 4.1869\n","Iteration: 10 of 27\ttrain_loss: 4.4508\n","Iteration: 12 of 27\ttrain_loss: 4.6421\n","Iteration: 14 of 27\ttrain_loss: 4.6294\n","Iteration: 16 of 27\ttrain_loss: 4.2604\n","Iteration: 18 of 27\ttrain_loss: 4.7105\n","Iteration: 20 of 27\ttrain_loss: 4.5238\n","Iteration: 22 of 27\ttrain_loss: 4.3272\n","Iteration: 24 of 27\ttrain_loss: 4.4338\n","Iteration: 26 of 27\ttrain_loss: 4.3347\n","Iteration: 27 of 27\ttrain_loss: 4.0186\n","Average Score for this Epoch: 4.486234188079834\n","--- new best score ---\n","\n","\n","-------------------- Epoch 28 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 4.3614\n","Iteration: 2 of 27\ttrain_loss: 4.3581\n","Iteration: 4 of 27\ttrain_loss: 4.5526\n","Iteration: 6 of 27\ttrain_loss: 4.6063\n","Iteration: 8 of 27\ttrain_loss: 4.2892\n","Iteration: 10 of 27\ttrain_loss: 4.2563\n","Iteration: 12 of 27\ttrain_loss: 4.4523\n","Iteration: 14 of 27\ttrain_loss: 4.4758\n","Iteration: 16 of 27\ttrain_loss: 4.4773\n","Iteration: 18 of 27\ttrain_loss: 4.4437\n","Iteration: 20 of 27\ttrain_loss: 4.6040\n","Iteration: 22 of 27\ttrain_loss: 4.4356\n","Iteration: 24 of 27\ttrain_loss: 4.2961\n","Iteration: 26 of 27\ttrain_loss: 4.6513\n","Iteration: 27 of 27\ttrain_loss: 4.3673\n","Average Score for this Epoch: 4.4028801918029785\n","--- new best score ---\n","\n","\n","-------------------- Epoch 29 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 4.4544\n","Iteration: 2 of 27\ttrain_loss: 4.2395\n","Iteration: 4 of 27\ttrain_loss: 4.2645\n","Iteration: 6 of 27\ttrain_loss: 4.5738\n","Iteration: 8 of 27\ttrain_loss: 4.3888\n","Iteration: 10 of 27\ttrain_loss: 4.0443\n","Iteration: 12 of 27\ttrain_loss: 4.7523\n","Iteration: 14 of 27\ttrain_loss: 4.2503\n","Iteration: 16 of 27\ttrain_loss: 4.3958\n","Iteration: 18 of 27\ttrain_loss: 4.5617\n","Iteration: 20 of 27\ttrain_loss: 4.3636\n","Iteration: 22 of 27\ttrain_loss: 4.3108\n","Iteration: 24 of 27\ttrain_loss: 4.6914\n","Iteration: 26 of 27\ttrain_loss: 4.4727\n","Iteration: 27 of 27\ttrain_loss: 4.4399\n","Average Score for this Epoch: 4.425745487213135\n","-------------------- Epoch 30 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 4.4383\n","Iteration: 2 of 27\ttrain_loss: 4.4727\n","Iteration: 4 of 27\ttrain_loss: 4.3729\n","Iteration: 6 of 27\ttrain_loss: 4.7496\n","Iteration: 8 of 27\ttrain_loss: 4.3406\n","Iteration: 10 of 27\ttrain_loss: 4.2205\n","Iteration: 12 of 27\ttrain_loss: 4.3093\n","Iteration: 14 of 27\ttrain_loss: 4.2987\n","Iteration: 16 of 27\ttrain_loss: 4.2966\n","Iteration: 18 of 27\ttrain_loss: 4.4400\n","Iteration: 20 of 27\ttrain_loss: 4.4473\n","Iteration: 22 of 27\ttrain_loss: 4.4402\n","Iteration: 24 of 27\ttrain_loss: 4.8595\n","Iteration: 26 of 27\ttrain_loss: 4.7209\n","Iteration: 27 of 27\ttrain_loss: 4.4312\n","Average Score for this Epoch: 4.406260013580322\n","-------------------- Epoch 31 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 4.3544\n","Iteration: 2 of 27\ttrain_loss: 4.4409\n","Iteration: 4 of 27\ttrain_loss: 4.0867\n","Iteration: 6 of 27\ttrain_loss: 4.4311\n","Iteration: 8 of 27\ttrain_loss: 4.3590\n","Iteration: 10 of 27\ttrain_loss: 4.2465\n","Iteration: 12 of 27\ttrain_loss: 4.2015\n","Iteration: 14 of 27\ttrain_loss: 4.4303\n","Iteration: 16 of 27\ttrain_loss: 4.1414\n","Iteration: 18 of 27\ttrain_loss: 4.2143\n","Iteration: 20 of 27\ttrain_loss: 4.6616\n","Iteration: 22 of 27\ttrain_loss: 4.5717\n","Iteration: 24 of 27\ttrain_loss: 4.6565\n","Iteration: 26 of 27\ttrain_loss: 4.4052\n","Iteration: 27 of 27\ttrain_loss: 4.3352\n","Average Score for this Epoch: 4.389413356781006\n","--- new best score ---\n","\n","\n","-------------------- Epoch 32 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 4.2202\n","Iteration: 2 of 27\ttrain_loss: 4.1176\n","Iteration: 4 of 27\ttrain_loss: 4.3816\n","Iteration: 6 of 27\ttrain_loss: 4.2702\n","Iteration: 8 of 27\ttrain_loss: 4.5396\n","Iteration: 10 of 27\ttrain_loss: 4.3664\n","Iteration: 12 of 27\ttrain_loss: 4.1530\n","Iteration: 14 of 27\ttrain_loss: 4.2759\n","Iteration: 16 of 27\ttrain_loss: 4.5122\n","Iteration: 18 of 27\ttrain_loss: 4.3379\n","Iteration: 20 of 27\ttrain_loss: 4.3096\n","Iteration: 22 of 27\ttrain_loss: 4.5156\n","Iteration: 24 of 27\ttrain_loss: 4.2869\n","Iteration: 26 of 27\ttrain_loss: 4.5442\n","Iteration: 27 of 27\ttrain_loss: 4.2426\n","Average Score for this Epoch: 4.337841510772705\n","--- new best score ---\n","\n","\n","-------------------- Epoch 33 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 4.0510\n","Iteration: 2 of 27\ttrain_loss: 4.0750\n","Iteration: 4 of 27\ttrain_loss: 4.1319\n","Iteration: 6 of 27\ttrain_loss: 3.9446\n","Iteration: 8 of 27\ttrain_loss: 4.1289\n","Iteration: 10 of 27\ttrain_loss: 4.0185\n","Iteration: 12 of 27\ttrain_loss: 4.2462\n","Iteration: 14 of 27\ttrain_loss: 4.3219\n","Iteration: 16 of 27\ttrain_loss: 4.4440\n","Iteration: 18 of 27\ttrain_loss: 4.2344\n","Iteration: 20 of 27\ttrain_loss: 4.0551\n","Iteration: 22 of 27\ttrain_loss: 4.1500\n","Iteration: 24 of 27\ttrain_loss: 4.3433\n","Iteration: 26 of 27\ttrain_loss: 4.1095\n","Iteration: 27 of 27\ttrain_loss: 3.8354\n","Average Score for this Epoch: 4.199780464172363\n","--- new best score ---\n","\n","\n","-------------------- Epoch 34 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 3.9604\n","Iteration: 2 of 27\ttrain_loss: 3.9366\n","Iteration: 4 of 27\ttrain_loss: 3.8125\n","Iteration: 6 of 27\ttrain_loss: 4.1998\n","Iteration: 8 of 27\ttrain_loss: 4.0650\n","Iteration: 10 of 27\ttrain_loss: 4.2195\n","Iteration: 12 of 27\ttrain_loss: 4.1880\n","Iteration: 14 of 27\ttrain_loss: 4.0150\n","Iteration: 16 of 27\ttrain_loss: 4.1468\n","Iteration: 18 of 27\ttrain_loss: 3.8560\n","Iteration: 20 of 27\ttrain_loss: 3.9697\n","Iteration: 22 of 27\ttrain_loss: 4.2926\n","Iteration: 24 of 27\ttrain_loss: 4.2084\n","Iteration: 26 of 27\ttrain_loss: 4.0449\n","Iteration: 27 of 27\ttrain_loss: 3.8621\n","Average Score for this Epoch: 4.049721717834473\n","--- new best score ---\n","\n","\n","-------------------- Epoch 35 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 3.8071\n","Iteration: 2 of 27\ttrain_loss: 3.6711\n","Iteration: 4 of 27\ttrain_loss: 4.0663\n","Iteration: 6 of 27\ttrain_loss: 4.0284\n","Iteration: 8 of 27\ttrain_loss: 3.9488\n","Iteration: 10 of 27\ttrain_loss: 4.1049\n","Iteration: 12 of 27\ttrain_loss: 3.8142\n","Iteration: 14 of 27\ttrain_loss: 3.8538\n","Iteration: 16 of 27\ttrain_loss: 4.0143\n","Iteration: 18 of 27\ttrain_loss: 3.9784\n","Iteration: 20 of 27\ttrain_loss: 4.0863\n","Iteration: 22 of 27\ttrain_loss: 3.7597\n","Iteration: 24 of 27\ttrain_loss: 4.2863\n","Iteration: 26 of 27\ttrain_loss: 3.8768\n","Iteration: 27 of 27\ttrain_loss: 3.8302\n","Average Score for this Epoch: 3.9293339252471924\n","--- new best score ---\n","\n","\n","-------------------- Epoch 36 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 3.9066\n","Iteration: 2 of 27\ttrain_loss: 3.7367\n","Iteration: 4 of 27\ttrain_loss: 3.7493\n","Iteration: 6 of 27\ttrain_loss: 3.9260\n","Iteration: 8 of 27\ttrain_loss: 4.0342\n","Iteration: 10 of 27\ttrain_loss: 4.1203\n","Iteration: 12 of 27\ttrain_loss: 3.7991\n","Iteration: 14 of 27\ttrain_loss: 3.7553\n","Iteration: 16 of 27\ttrain_loss: 3.7764\n","Iteration: 18 of 27\ttrain_loss: 4.1516\n","Iteration: 20 of 27\ttrain_loss: 3.7073\n","Iteration: 22 of 27\ttrain_loss: 4.1088\n","Iteration: 24 of 27\ttrain_loss: 3.7330\n","Iteration: 26 of 27\ttrain_loss: 3.7641\n","Iteration: 27 of 27\ttrain_loss: 3.9216\n","Average Score for this Epoch: 3.918888568878174\n","--- new best score ---\n","\n","\n","-------------------- Epoch 37 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 3.9182\n","Iteration: 2 of 27\ttrain_loss: 3.8633\n","Iteration: 4 of 27\ttrain_loss: 3.7182\n","Iteration: 6 of 27\ttrain_loss: 3.7074\n","Iteration: 8 of 27\ttrain_loss: 3.6912\n","Iteration: 10 of 27\ttrain_loss: 3.6724\n","Iteration: 12 of 27\ttrain_loss: 3.8998\n","Iteration: 14 of 27\ttrain_loss: 4.1287\n","Iteration: 16 of 27\ttrain_loss: 3.8967\n","Iteration: 18 of 27\ttrain_loss: 3.8886\n","Iteration: 20 of 27\ttrain_loss: 3.9666\n","Iteration: 22 of 27\ttrain_loss: 3.9830\n","Iteration: 24 of 27\ttrain_loss: 4.1586\n","Iteration: 26 of 27\ttrain_loss: 4.0625\n","Iteration: 27 of 27\ttrain_loss: 3.8711\n","Average Score for this Epoch: 3.9048783779144287\n","--- new best score ---\n","\n","\n","-------------------- Epoch 38 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 3.8298\n","Iteration: 2 of 27\ttrain_loss: 3.8797\n","Iteration: 4 of 27\ttrain_loss: 3.6063\n","Iteration: 6 of 27\ttrain_loss: 3.6374\n","Iteration: 8 of 27\ttrain_loss: 3.7318\n","Iteration: 10 of 27\ttrain_loss: 3.9661\n","Iteration: 12 of 27\ttrain_loss: 3.9783\n","Iteration: 14 of 27\ttrain_loss: 3.7963\n","Iteration: 16 of 27\ttrain_loss: 4.0687\n","Iteration: 18 of 27\ttrain_loss: 3.6244\n","Iteration: 20 of 27\ttrain_loss: 3.7308\n","Iteration: 22 of 27\ttrain_loss: 3.9923\n","Iteration: 24 of 27\ttrain_loss: 4.2431\n","Iteration: 26 of 27\ttrain_loss: 4.3847\n","Iteration: 27 of 27\ttrain_loss: 3.8187\n","Average Score for this Epoch: 3.883570909500122\n","--- new best score ---\n","\n","\n","-------------------- Epoch 39 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 3.7630\n","Iteration: 2 of 27\ttrain_loss: 3.4681\n","Iteration: 4 of 27\ttrain_loss: 3.4090\n","Iteration: 6 of 27\ttrain_loss: 3.8974\n","Iteration: 8 of 27\ttrain_loss: 3.6286\n","Iteration: 10 of 27\ttrain_loss: 4.0031\n","Iteration: 12 of 27\ttrain_loss: 3.9818\n","Iteration: 14 of 27\ttrain_loss: 3.9528\n","Iteration: 16 of 27\ttrain_loss: 3.8996\n","Iteration: 18 of 27\ttrain_loss: 3.9595\n","Iteration: 20 of 27\ttrain_loss: 3.7146\n","Iteration: 22 of 27\ttrain_loss: 3.9012\n","Iteration: 24 of 27\ttrain_loss: 4.1406\n","Iteration: 26 of 27\ttrain_loss: 4.2377\n","Iteration: 27 of 27\ttrain_loss: 3.6760\n","Average Score for this Epoch: 3.8624329566955566\n","--- new best score ---\n","\n","\n","-------------------- Epoch 40 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 3.6819\n","Iteration: 2 of 27\ttrain_loss: 3.3972\n","Iteration: 4 of 27\ttrain_loss: 3.9841\n","Iteration: 6 of 27\ttrain_loss: 3.8567\n","Iteration: 8 of 27\ttrain_loss: 3.7846\n","Iteration: 10 of 27\ttrain_loss: 3.6029\n","Iteration: 12 of 27\ttrain_loss: 3.5537\n","Iteration: 14 of 27\ttrain_loss: 3.9305\n","Iteration: 16 of 27\ttrain_loss: 4.1643\n","Iteration: 18 of 27\ttrain_loss: 3.8870\n","Iteration: 20 of 27\ttrain_loss: 3.5232\n","Iteration: 22 of 27\ttrain_loss: 3.6065\n","Iteration: 24 of 27\ttrain_loss: 3.7288\n","Iteration: 26 of 27\ttrain_loss: 3.7895\n","Iteration: 27 of 27\ttrain_loss: 3.3910\n","Average Score for this Epoch: 3.7288711071014404\n","--- new best score ---\n","\n","\n","-------------------- Epoch 41 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 3.7335\n","Iteration: 2 of 27\ttrain_loss: 3.4313\n","Iteration: 4 of 27\ttrain_loss: 3.3484\n","Iteration: 6 of 27\ttrain_loss: 3.4646\n","Iteration: 8 of 27\ttrain_loss: 3.3448\n","Iteration: 10 of 27\ttrain_loss: 3.4380\n","Iteration: 12 of 27\ttrain_loss: 3.7853\n","Iteration: 14 of 27\ttrain_loss: 3.5968\n","Iteration: 16 of 27\ttrain_loss: 3.6780\n","Iteration: 18 of 27\ttrain_loss: 3.7250\n","Iteration: 20 of 27\ttrain_loss: 3.6221\n","Iteration: 22 of 27\ttrain_loss: 3.7378\n","Iteration: 24 of 27\ttrain_loss: 3.8118\n","Iteration: 26 of 27\ttrain_loss: 3.6499\n","Iteration: 27 of 27\ttrain_loss: 3.3687\n","Average Score for this Epoch: 3.5510787963867188\n","--- new best score ---\n","\n","\n","-------------------- Epoch 42 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 3.6568\n","Iteration: 2 of 27\ttrain_loss: 3.3724\n","Iteration: 4 of 27\ttrain_loss: 3.2602\n","Iteration: 6 of 27\ttrain_loss: 3.2362\n","Iteration: 8 of 27\ttrain_loss: 3.5470\n","Iteration: 10 of 27\ttrain_loss: 3.0197\n","Iteration: 12 of 27\ttrain_loss: 3.1882\n","Iteration: 14 of 27\ttrain_loss: 3.7780\n","Iteration: 16 of 27\ttrain_loss: 4.0256\n","Iteration: 18 of 27\ttrain_loss: 3.2407\n","Iteration: 20 of 27\ttrain_loss: 3.2684\n","Iteration: 22 of 27\ttrain_loss: 3.5728\n","Iteration: 24 of 27\ttrain_loss: 3.4948\n","Iteration: 26 of 27\ttrain_loss: 3.5727\n","Iteration: 27 of 27\ttrain_loss: 3.5097\n","Average Score for this Epoch: 3.436600923538208\n","--- new best score ---\n","\n","\n","-------------------- Epoch 43 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 3.1272\n","Iteration: 2 of 27\ttrain_loss: 3.5647\n","Iteration: 4 of 27\ttrain_loss: 2.9355\n","Iteration: 6 of 27\ttrain_loss: 3.3144\n","Iteration: 8 of 27\ttrain_loss: 3.3392\n","Iteration: 10 of 27\ttrain_loss: 3.4532\n","Iteration: 12 of 27\ttrain_loss: 3.1663\n","Iteration: 14 of 27\ttrain_loss: 2.9985\n","Iteration: 16 of 27\ttrain_loss: 3.2714\n","Iteration: 18 of 27\ttrain_loss: 3.9584\n","Iteration: 20 of 27\ttrain_loss: 3.7782\n","Iteration: 22 of 27\ttrain_loss: 3.4750\n","Iteration: 24 of 27\ttrain_loss: 3.6449\n","Iteration: 26 of 27\ttrain_loss: 3.3211\n","Iteration: 27 of 27\ttrain_loss: 3.1793\n","Average Score for this Epoch: 3.377401828765869\n","--- new best score ---\n","\n","\n","-------------------- Epoch 44 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 3.3320\n","Iteration: 2 of 27\ttrain_loss: 3.3370\n","Iteration: 4 of 27\ttrain_loss: 3.8432\n","Iteration: 6 of 27\ttrain_loss: 3.2916\n","Iteration: 8 of 27\ttrain_loss: 3.1057\n","Iteration: 10 of 27\ttrain_loss: 3.4135\n","Iteration: 12 of 27\ttrain_loss: 3.1644\n","Iteration: 14 of 27\ttrain_loss: 3.8501\n","Iteration: 16 of 27\ttrain_loss: 3.2179\n","Iteration: 18 of 27\ttrain_loss: 3.4683\n","Iteration: 20 of 27\ttrain_loss: 3.7637\n","Iteration: 22 of 27\ttrain_loss: 3.1857\n","Iteration: 24 of 27\ttrain_loss: 3.3733\n","Iteration: 26 of 27\ttrain_loss: 3.3578\n","Iteration: 27 of 27\ttrain_loss: 3.3652\n","Average Score for this Epoch: 3.390962839126587\n","-------------------- Epoch 45 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 3.2448\n","Iteration: 2 of 27\ttrain_loss: 3.7227\n","Iteration: 4 of 27\ttrain_loss: 3.4647\n","Iteration: 6 of 27\ttrain_loss: 3.2483\n","Iteration: 8 of 27\ttrain_loss: 3.1463\n","Iteration: 10 of 27\ttrain_loss: 3.1001\n","Iteration: 12 of 27\ttrain_loss: 3.3620\n","Iteration: 14 of 27\ttrain_loss: 3.3242\n","Iteration: 16 of 27\ttrain_loss: 3.1305\n","Iteration: 18 of 27\ttrain_loss: 3.3690\n","Iteration: 20 of 27\ttrain_loss: 3.5354\n","Iteration: 22 of 27\ttrain_loss: 3.6100\n","Iteration: 24 of 27\ttrain_loss: 3.6255\n","Iteration: 26 of 27\ttrain_loss: 3.1261\n","Iteration: 27 of 27\ttrain_loss: 3.1638\n","Average Score for this Epoch: 3.3698441982269287\n","--- new best score ---\n","\n","\n","-------------------- Epoch 46 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 3.8115\n","Iteration: 2 of 27\ttrain_loss: 3.1696\n","Iteration: 4 of 27\ttrain_loss: 3.2383\n","Iteration: 6 of 27\ttrain_loss: 3.3097\n","Iteration: 8 of 27\ttrain_loss: 3.2573\n","Iteration: 10 of 27\ttrain_loss: 3.3944\n","Iteration: 12 of 27\ttrain_loss: 3.4304\n","Iteration: 14 of 27\ttrain_loss: 2.9957\n","Iteration: 16 of 27\ttrain_loss: 3.1536\n","Iteration: 18 of 27\ttrain_loss: 3.2169\n","Iteration: 20 of 27\ttrain_loss: 3.2884\n","Iteration: 22 of 27\ttrain_loss: 3.2436\n","Iteration: 24 of 27\ttrain_loss: 3.4225\n","Iteration: 26 of 27\ttrain_loss: 3.6773\n","Iteration: 27 of 27\ttrain_loss: 3.6291\n","Average Score for this Epoch: 3.382741689682007\n","-------------------- Epoch 47 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 3.4292\n","Iteration: 2 of 27\ttrain_loss: 3.0039\n","Iteration: 4 of 27\ttrain_loss: 2.6451\n","Iteration: 6 of 27\ttrain_loss: 3.4474\n","Iteration: 8 of 27\ttrain_loss: 3.2588\n","Iteration: 10 of 27\ttrain_loss: 3.1622\n","Iteration: 12 of 27\ttrain_loss: 3.1773\n","Iteration: 14 of 27\ttrain_loss: 3.3035\n","Iteration: 16 of 27\ttrain_loss: 3.9918\n","Iteration: 18 of 27\ttrain_loss: 3.5822\n","Iteration: 20 of 27\ttrain_loss: 3.4947\n","Iteration: 22 of 27\ttrain_loss: 2.9315\n","Iteration: 24 of 27\ttrain_loss: 3.5869\n","Iteration: 26 of 27\ttrain_loss: 3.3114\n","Iteration: 27 of 27\ttrain_loss: 3.3360\n","Average Score for this Epoch: 3.2686781883239746\n","--- new best score ---\n","\n","\n","-------------------- Epoch 48 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 2.5516\n","Iteration: 2 of 27\ttrain_loss: 3.1483\n","Iteration: 4 of 27\ttrain_loss: 2.8741\n","Iteration: 6 of 27\ttrain_loss: 3.0987\n","Iteration: 8 of 27\ttrain_loss: 3.5446\n","Iteration: 10 of 27\ttrain_loss: 3.0138\n","Iteration: 12 of 27\ttrain_loss: 3.0833\n","Iteration: 14 of 27\ttrain_loss: 2.7731\n","Iteration: 16 of 27\ttrain_loss: 3.4595\n","Iteration: 18 of 27\ttrain_loss: 3.1777\n","Iteration: 20 of 27\ttrain_loss: 3.3296\n","Iteration: 22 of 27\ttrain_loss: 3.1339\n","Iteration: 24 of 27\ttrain_loss: 3.3025\n","Iteration: 26 of 27\ttrain_loss: 2.8582\n","Iteration: 27 of 27\ttrain_loss: 2.3867\n","Average Score for this Epoch: 3.0724563598632812\n","--- new best score ---\n","\n","\n","-------------------- Epoch 49 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 2.9051\n","Iteration: 2 of 27\ttrain_loss: 3.2647\n","Iteration: 4 of 27\ttrain_loss: 3.0099\n","Iteration: 6 of 27\ttrain_loss: 2.8832\n","Iteration: 8 of 27\ttrain_loss: 3.1015\n","Iteration: 10 of 27\ttrain_loss: 2.9261\n","Iteration: 12 of 27\ttrain_loss: 2.9088\n","Iteration: 14 of 27\ttrain_loss: 3.0425\n","Iteration: 16 of 27\ttrain_loss: 3.1245\n","Iteration: 18 of 27\ttrain_loss: 3.0224\n","Iteration: 20 of 27\ttrain_loss: 2.8128\n","Iteration: 22 of 27\ttrain_loss: 2.9165\n","Iteration: 24 of 27\ttrain_loss: 2.5820\n","Iteration: 26 of 27\ttrain_loss: 2.9568\n","Iteration: 27 of 27\ttrain_loss: 2.7822\n","Average Score for this Epoch: 2.949181079864502\n","--- new best score ---\n","\n","\n","-------------------- Epoch 50 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 2.8635\n","Iteration: 2 of 27\ttrain_loss: 3.4338\n","Iteration: 4 of 27\ttrain_loss: 2.6110\n","Iteration: 6 of 27\ttrain_loss: 3.0916\n","Iteration: 8 of 27\ttrain_loss: 2.9276\n","Iteration: 10 of 27\ttrain_loss: 2.7428\n","Iteration: 12 of 27\ttrain_loss: 2.8834\n","Iteration: 14 of 27\ttrain_loss: 2.5309\n","Iteration: 16 of 27\ttrain_loss: 2.6250\n","Iteration: 18 of 27\ttrain_loss: 3.0122\n","Iteration: 20 of 27\ttrain_loss: 2.7563\n","Iteration: 22 of 27\ttrain_loss: 2.5809\n","Iteration: 24 of 27\ttrain_loss: 3.0932\n","Iteration: 26 of 27\ttrain_loss: 2.9389\n","Iteration: 27 of 27\ttrain_loss: 2.9699\n","Average Score for this Epoch: 2.8938796520233154\n","--- new best score ---\n","\n","\n","-------------------- Epoch 51 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 3.0002\n","Iteration: 2 of 27\ttrain_loss: 2.5773\n","Iteration: 4 of 27\ttrain_loss: 2.5855\n","Iteration: 6 of 27\ttrain_loss: 3.2808\n","Iteration: 8 of 27\ttrain_loss: 3.0216\n","Iteration: 10 of 27\ttrain_loss: 2.6105\n","Iteration: 12 of 27\ttrain_loss: 3.4016\n","Iteration: 14 of 27\ttrain_loss: 2.5174\n","Iteration: 16 of 27\ttrain_loss: 2.7303\n","Iteration: 18 of 27\ttrain_loss: 3.1562\n","Iteration: 20 of 27\ttrain_loss: 2.9191\n","Iteration: 22 of 27\ttrain_loss: 2.8969\n","Iteration: 24 of 27\ttrain_loss: 3.2674\n","Iteration: 26 of 27\ttrain_loss: 3.1849\n","Iteration: 27 of 27\ttrain_loss: 2.8583\n","Average Score for this Epoch: 2.916637420654297\n","-------------------- Epoch 52 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 2.8729\n","Iteration: 2 of 27\ttrain_loss: 3.0956\n","Iteration: 4 of 27\ttrain_loss: 3.2805\n","Iteration: 6 of 27\ttrain_loss: 3.0101\n","Iteration: 8 of 27\ttrain_loss: 2.8318\n","Iteration: 10 of 27\ttrain_loss: 3.1640\n","Iteration: 12 of 27\ttrain_loss: 2.3448\n","Iteration: 14 of 27\ttrain_loss: 2.9599\n","Iteration: 16 of 27\ttrain_loss: 3.1101\n","Iteration: 18 of 27\ttrain_loss: 2.9160\n","Iteration: 20 of 27\ttrain_loss: 2.6349\n","Iteration: 22 of 27\ttrain_loss: 3.0033\n","Iteration: 24 of 27\ttrain_loss: 3.0044\n","Iteration: 26 of 27\ttrain_loss: 3.0114\n","Iteration: 27 of 27\ttrain_loss: 3.0798\n","Average Score for this Epoch: 2.9068286418914795\n","-------------------- Epoch 53 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 3.2235\n","Iteration: 2 of 27\ttrain_loss: 2.7428\n","Iteration: 4 of 27\ttrain_loss: 3.2744\n","Iteration: 6 of 27\ttrain_loss: 2.3275\n","Iteration: 8 of 27\ttrain_loss: 2.9415\n","Iteration: 10 of 27\ttrain_loss: 2.4528\n","Iteration: 12 of 27\ttrain_loss: 2.9028\n","Iteration: 14 of 27\ttrain_loss: 3.1049\n","Iteration: 16 of 27\ttrain_loss: 2.9344\n","Iteration: 18 of 27\ttrain_loss: 2.7563\n","Iteration: 20 of 27\ttrain_loss: 3.2701\n","Iteration: 22 of 27\ttrain_loss: 3.2604\n","Iteration: 24 of 27\ttrain_loss: 3.5096\n","Iteration: 26 of 27\ttrain_loss: 2.7056\n","Iteration: 27 of 27\ttrain_loss: 3.2294\n","Average Score for this Epoch: 2.9254300594329834\n","-------------------- Epoch 54 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 2.2448\n","Iteration: 2 of 27\ttrain_loss: 2.7861\n","Iteration: 4 of 27\ttrain_loss: 2.9518\n","Iteration: 6 of 27\ttrain_loss: 2.8775\n","Iteration: 8 of 27\ttrain_loss: 2.8887\n","Iteration: 10 of 27\ttrain_loss: 2.6302\n","Iteration: 12 of 27\ttrain_loss: 2.5665\n","Iteration: 14 of 27\ttrain_loss: 3.2031\n","Iteration: 16 of 27\ttrain_loss: 3.1513\n","Iteration: 18 of 27\ttrain_loss: 2.8803\n","Iteration: 20 of 27\ttrain_loss: 3.0210\n","Iteration: 22 of 27\ttrain_loss: 3.2200\n","Iteration: 24 of 27\ttrain_loss: 2.7835\n","Iteration: 26 of 27\ttrain_loss: 2.6864\n","Iteration: 27 of 27\ttrain_loss: 1.8941\n","Average Score for this Epoch: 2.8423428535461426\n","--- new best score ---\n","\n","\n","-------------------- Epoch 55 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 2.5297\n","Iteration: 2 of 27\ttrain_loss: 2.4307\n","Iteration: 4 of 27\ttrain_loss: 2.5829\n","Iteration: 6 of 27\ttrain_loss: 2.3520\n","Iteration: 8 of 27\ttrain_loss: 2.5360\n","Iteration: 10 of 27\ttrain_loss: 2.7257\n","Iteration: 12 of 27\ttrain_loss: 2.7959\n","Iteration: 14 of 27\ttrain_loss: 3.0727\n","Iteration: 16 of 27\ttrain_loss: 2.8606\n","Iteration: 18 of 27\ttrain_loss: 3.4886\n","Iteration: 20 of 27\ttrain_loss: 2.7716\n","Iteration: 22 of 27\ttrain_loss: 2.6050\n","Iteration: 24 of 27\ttrain_loss: 2.9690\n","Iteration: 26 of 27\ttrain_loss: 2.8980\n","Iteration: 27 of 27\ttrain_loss: 2.2938\n","Average Score for this Epoch: 2.6914448738098145\n","--- new best score ---\n","\n","\n","-------------------- Epoch 56 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 2.6940\n","Iteration: 2 of 27\ttrain_loss: 2.8296\n","Iteration: 4 of 27\ttrain_loss: 2.5627\n","Iteration: 6 of 27\ttrain_loss: 2.5427\n","Iteration: 8 of 27\ttrain_loss: 2.2616\n","Iteration: 10 of 27\ttrain_loss: 2.4732\n","Iteration: 12 of 27\ttrain_loss: 2.8990\n","Iteration: 14 of 27\ttrain_loss: 2.3682\n","Iteration: 16 of 27\ttrain_loss: 2.7692\n","Iteration: 18 of 27\ttrain_loss: 2.4716\n","Iteration: 20 of 27\ttrain_loss: 2.7075\n","Iteration: 22 of 27\ttrain_loss: 2.6744\n","Iteration: 24 of 27\ttrain_loss: 2.7505\n","Iteration: 26 of 27\ttrain_loss: 2.2570\n","Iteration: 27 of 27\ttrain_loss: 2.4940\n","Average Score for this Epoch: 2.6052286624908447\n","--- new best score ---\n","\n","\n","-------------------- Epoch 57 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 2.3906\n","Iteration: 2 of 27\ttrain_loss: 2.5266\n","Iteration: 4 of 27\ttrain_loss: 2.5281\n","Iteration: 6 of 27\ttrain_loss: 2.6367\n","Iteration: 8 of 27\ttrain_loss: 2.7077\n","Iteration: 10 of 27\ttrain_loss: 2.2687\n","Iteration: 12 of 27\ttrain_loss: 2.5908\n","Iteration: 14 of 27\ttrain_loss: 1.9837\n","Iteration: 16 of 27\ttrain_loss: 2.9594\n","Iteration: 18 of 27\ttrain_loss: 2.3613\n","Iteration: 20 of 27\ttrain_loss: 2.5665\n","Iteration: 22 of 27\ttrain_loss: 3.1371\n","Iteration: 24 of 27\ttrain_loss: 2.4210\n","Iteration: 26 of 27\ttrain_loss: 2.2642\n","Iteration: 27 of 27\ttrain_loss: 2.3633\n","Average Score for this Epoch: 2.5182454586029053\n","--- new best score ---\n","\n","\n","-------------------- Epoch 58 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 2.3097\n","Iteration: 2 of 27\ttrain_loss: 2.6778\n","Iteration: 4 of 27\ttrain_loss: 2.4631\n","Iteration: 6 of 27\ttrain_loss: 2.5335\n","Iteration: 8 of 27\ttrain_loss: 2.3224\n","Iteration: 10 of 27\ttrain_loss: 3.0008\n","Iteration: 12 of 27\ttrain_loss: 2.3780\n","Iteration: 14 of 27\ttrain_loss: 2.7970\n","Iteration: 16 of 27\ttrain_loss: 2.1119\n","Iteration: 18 of 27\ttrain_loss: 2.4745\n","Iteration: 20 of 27\ttrain_loss: 2.4866\n","Iteration: 22 of 27\ttrain_loss: 2.5930\n","Iteration: 24 of 27\ttrain_loss: 2.2483\n","Iteration: 26 of 27\ttrain_loss: 2.8055\n","Iteration: 27 of 27\ttrain_loss: 2.3139\n","Average Score for this Epoch: 2.5275211334228516\n","-------------------- Epoch 59 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 2.7493\n","Iteration: 2 of 27\ttrain_loss: 2.4776\n","Iteration: 4 of 27\ttrain_loss: 2.3868\n","Iteration: 6 of 27\ttrain_loss: 2.6751\n","Iteration: 8 of 27\ttrain_loss: 2.2356\n","Iteration: 10 of 27\ttrain_loss: 2.2601\n","Iteration: 12 of 27\ttrain_loss: 3.1171\n","Iteration: 14 of 27\ttrain_loss: 2.2569\n","Iteration: 16 of 27\ttrain_loss: 2.7022\n","Iteration: 18 of 27\ttrain_loss: 3.1601\n","Iteration: 20 of 27\ttrain_loss: 2.2618\n","Iteration: 22 of 27\ttrain_loss: 2.4231\n","Iteration: 24 of 27\ttrain_loss: 1.9640\n","Iteration: 26 of 27\ttrain_loss: 2.7533\n","Iteration: 27 of 27\ttrain_loss: 2.6933\n","Average Score for this Epoch: 2.5322985649108887\n","-------------------- Epoch 60 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 2.3713\n","Iteration: 2 of 27\ttrain_loss: 1.8998\n","Iteration: 4 of 27\ttrain_loss: 2.3939\n","Iteration: 6 of 27\ttrain_loss: 2.3272\n","Iteration: 8 of 27\ttrain_loss: 2.4149\n","Iteration: 10 of 27\ttrain_loss: 2.6228\n","Iteration: 12 of 27\ttrain_loss: 2.6396\n","Iteration: 14 of 27\ttrain_loss: 2.8256\n","Iteration: 16 of 27\ttrain_loss: 2.5852\n","Iteration: 18 of 27\ttrain_loss: 2.8645\n","Iteration: 20 of 27\ttrain_loss: 2.5054\n","Iteration: 22 of 27\ttrain_loss: 2.7220\n","Iteration: 24 of 27\ttrain_loss: 2.9713\n","Iteration: 26 of 27\ttrain_loss: 2.6443\n","Iteration: 27 of 27\ttrain_loss: 2.4243\n","Average Score for this Epoch: 2.567017078399658\n","-------------------- Epoch 61 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 2.2955\n","Iteration: 2 of 27\ttrain_loss: 2.3653\n","Iteration: 4 of 27\ttrain_loss: 1.8659\n","Iteration: 6 of 27\ttrain_loss: 2.5834\n","Iteration: 8 of 27\ttrain_loss: 2.2332\n","Iteration: 10 of 27\ttrain_loss: 2.4165\n","Iteration: 12 of 27\ttrain_loss: 2.4104\n","Iteration: 14 of 27\ttrain_loss: 2.6759\n","Iteration: 16 of 27\ttrain_loss: 2.2406\n","Iteration: 18 of 27\ttrain_loss: 2.3584\n","Iteration: 20 of 27\ttrain_loss: 2.6442\n","Iteration: 22 of 27\ttrain_loss: 2.4341\n","Iteration: 24 of 27\ttrain_loss: 2.4325\n","Iteration: 26 of 27\ttrain_loss: 2.8339\n","Iteration: 27 of 27\ttrain_loss: 2.2849\n","Average Score for this Epoch: 2.5286102294921875\n","-------------------- Epoch 62 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 2.8568\n","Iteration: 2 of 27\ttrain_loss: 2.0400\n","Iteration: 4 of 27\ttrain_loss: 2.5487\n","Iteration: 6 of 27\ttrain_loss: 2.0281\n","Iteration: 8 of 27\ttrain_loss: 3.3727\n","Iteration: 10 of 27\ttrain_loss: 1.7563\n","Iteration: 12 of 27\ttrain_loss: 1.8501\n","Iteration: 14 of 27\ttrain_loss: 2.3107\n","Iteration: 16 of 27\ttrain_loss: 2.3233\n","Iteration: 18 of 27\ttrain_loss: 2.3566\n","Iteration: 20 of 27\ttrain_loss: 2.5615\n","Iteration: 22 of 27\ttrain_loss: 1.8454\n","Iteration: 24 of 27\ttrain_loss: 2.4733\n","Iteration: 26 of 27\ttrain_loss: 2.1895\n","Iteration: 27 of 27\ttrain_loss: 2.6277\n","Average Score for this Epoch: 2.4230189323425293\n","--- new best score ---\n","\n","\n","-------------------- Epoch 63 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 2.7383\n","Iteration: 2 of 27\ttrain_loss: 2.2998\n","Iteration: 4 of 27\ttrain_loss: 2.3324\n","Iteration: 6 of 27\ttrain_loss: 2.6734\n","Iteration: 8 of 27\ttrain_loss: 1.9139\n","Iteration: 10 of 27\ttrain_loss: 2.3265\n","Iteration: 12 of 27\ttrain_loss: 2.3179\n","Iteration: 14 of 27\ttrain_loss: 3.0515\n","Iteration: 16 of 27\ttrain_loss: 2.3017\n","Iteration: 18 of 27\ttrain_loss: 2.2079\n","Iteration: 20 of 27\ttrain_loss: 2.0937\n","Iteration: 22 of 27\ttrain_loss: 2.8842\n","Iteration: 24 of 27\ttrain_loss: 2.1483\n","Iteration: 26 of 27\ttrain_loss: 1.8253\n","Iteration: 27 of 27\ttrain_loss: 2.6706\n","Average Score for this Epoch: 2.3399083614349365\n","--- new best score ---\n","\n","\n","-------------------- Epoch 64 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 2.2367\n","Iteration: 2 of 27\ttrain_loss: 2.7206\n","Iteration: 4 of 27\ttrain_loss: 2.0844\n","Iteration: 6 of 27\ttrain_loss: 2.0234\n","Iteration: 8 of 27\ttrain_loss: 2.0414\n","Iteration: 10 of 27\ttrain_loss: 1.7499\n","Iteration: 12 of 27\ttrain_loss: 2.4280\n","Iteration: 14 of 27\ttrain_loss: 2.1431\n","Iteration: 16 of 27\ttrain_loss: 2.3948\n","Iteration: 18 of 27\ttrain_loss: 2.0177\n","Iteration: 20 of 27\ttrain_loss: 2.3177\n","Iteration: 22 of 27\ttrain_loss: 2.3174\n","Iteration: 24 of 27\ttrain_loss: 2.3052\n","Iteration: 26 of 27\ttrain_loss: 2.1729\n","Iteration: 27 of 27\ttrain_loss: 2.2452\n","Average Score for this Epoch: 2.2160844802856445\n","--- new best score ---\n","\n","\n","-------------------- Epoch 65 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 2.5534\n","Iteration: 2 of 27\ttrain_loss: 1.7575\n","Iteration: 4 of 27\ttrain_loss: 2.0367\n","Iteration: 6 of 27\ttrain_loss: 2.2239\n","Iteration: 8 of 27\ttrain_loss: 2.3811\n","Iteration: 10 of 27\ttrain_loss: 2.4484\n","Iteration: 12 of 27\ttrain_loss: 1.8126\n","Iteration: 14 of 27\ttrain_loss: 1.4476\n","Iteration: 16 of 27\ttrain_loss: 2.4403\n","Iteration: 18 of 27\ttrain_loss: 2.0869\n","Iteration: 20 of 27\ttrain_loss: 2.3307\n","Iteration: 22 of 27\ttrain_loss: 2.4179\n","Iteration: 24 of 27\ttrain_loss: 2.5352\n","Iteration: 26 of 27\ttrain_loss: 2.9550\n","Iteration: 27 of 27\ttrain_loss: 2.3929\n","Average Score for this Epoch: 2.2306063175201416\n","-------------------- Epoch 66 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 1.5833\n","Iteration: 2 of 27\ttrain_loss: 2.0882\n","Iteration: 4 of 27\ttrain_loss: 2.0440\n","Iteration: 6 of 27\ttrain_loss: 2.3983\n","Iteration: 8 of 27\ttrain_loss: 2.5909\n","Iteration: 10 of 27\ttrain_loss: 2.0178\n","Iteration: 12 of 27\ttrain_loss: 2.1076\n","Iteration: 14 of 27\ttrain_loss: 2.0999\n","Iteration: 16 of 27\ttrain_loss: 2.4310\n","Iteration: 18 of 27\ttrain_loss: 2.0445\n","Iteration: 20 of 27\ttrain_loss: 3.2083\n","Iteration: 22 of 27\ttrain_loss: 1.9360\n","Iteration: 24 of 27\ttrain_loss: 1.9853\n","Iteration: 26 of 27\ttrain_loss: 2.2191\n","Iteration: 27 of 27\ttrain_loss: 1.5243\n","Average Score for this Epoch: 2.2104685306549072\n","--- new best score ---\n","\n","\n","-------------------- Epoch 67 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 2.1375\n","Iteration: 2 of 27\ttrain_loss: 2.3940\n","Iteration: 4 of 27\ttrain_loss: 2.2325\n","Iteration: 6 of 27\ttrain_loss: 2.2319\n","Iteration: 8 of 27\ttrain_loss: 2.0739\n","Iteration: 10 of 27\ttrain_loss: 2.6795\n","Iteration: 12 of 27\ttrain_loss: 2.3592\n","Iteration: 14 of 27\ttrain_loss: 2.7595\n","Iteration: 16 of 27\ttrain_loss: 2.4794\n","Iteration: 18 of 27\ttrain_loss: 2.0341\n","Iteration: 20 of 27\ttrain_loss: 2.4829\n","Iteration: 22 of 27\ttrain_loss: 2.4725\n","Iteration: 24 of 27\ttrain_loss: 2.7155\n","Iteration: 26 of 27\ttrain_loss: 2.5630\n","Iteration: 27 of 27\ttrain_loss: 2.1845\n","Average Score for this Epoch: 2.25795316696167\n","-------------------- Epoch 68 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 1.9026\n","Iteration: 2 of 27\ttrain_loss: 1.9759\n","Iteration: 4 of 27\ttrain_loss: 2.4356\n","Iteration: 6 of 27\ttrain_loss: 2.5221\n","Iteration: 8 of 27\ttrain_loss: 1.9174\n","Iteration: 10 of 27\ttrain_loss: 2.0534\n","Iteration: 12 of 27\ttrain_loss: 1.6349\n","Iteration: 14 of 27\ttrain_loss: 1.9156\n","Iteration: 16 of 27\ttrain_loss: 2.5859\n","Iteration: 18 of 27\ttrain_loss: 2.2674\n","Iteration: 20 of 27\ttrain_loss: 2.2075\n","Iteration: 22 of 27\ttrain_loss: 2.3816\n","Iteration: 24 of 27\ttrain_loss: 2.4439\n","Iteration: 26 of 27\ttrain_loss: 2.4698\n","Iteration: 27 of 27\ttrain_loss: 1.9974\n","Average Score for this Epoch: 2.209301710128784\n","--- new best score ---\n","\n","\n","-------------------- Epoch 69 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 2.5407\n","Iteration: 2 of 27\ttrain_loss: 1.9773\n","Iteration: 4 of 27\ttrain_loss: 2.4682\n","Iteration: 6 of 27\ttrain_loss: 1.8272\n","Iteration: 8 of 27\ttrain_loss: 2.2423\n","Iteration: 10 of 27\ttrain_loss: 2.0256\n","Iteration: 12 of 27\ttrain_loss: 1.9448\n","Iteration: 14 of 27\ttrain_loss: 2.4906\n","Iteration: 16 of 27\ttrain_loss: 1.9737\n","Iteration: 18 of 27\ttrain_loss: 2.0963\n","Iteration: 20 of 27\ttrain_loss: 1.9998\n","Iteration: 22 of 27\ttrain_loss: 2.3770\n","Iteration: 24 of 27\ttrain_loss: 2.1963\n","Iteration: 26 of 27\ttrain_loss: 1.6715\n","Iteration: 27 of 27\ttrain_loss: 2.4876\n","Average Score for this Epoch: 2.140265941619873\n","--- new best score ---\n","\n","\n","-------------------- Epoch 70 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 1.8400\n","Iteration: 2 of 27\ttrain_loss: 1.4967\n","Iteration: 4 of 27\ttrain_loss: 3.0810\n","Iteration: 6 of 27\ttrain_loss: 1.9335\n","Iteration: 8 of 27\ttrain_loss: 1.9184\n","Iteration: 10 of 27\ttrain_loss: 2.1309\n","Iteration: 12 of 27\ttrain_loss: 1.6570\n","Iteration: 14 of 27\ttrain_loss: 1.6482\n","Iteration: 16 of 27\ttrain_loss: 1.9260\n","Iteration: 18 of 27\ttrain_loss: 2.3338\n","Iteration: 20 of 27\ttrain_loss: 2.1040\n","Iteration: 22 of 27\ttrain_loss: 2.1789\n","Iteration: 24 of 27\ttrain_loss: 2.0737\n","Iteration: 26 of 27\ttrain_loss: 2.9005\n","Iteration: 27 of 27\ttrain_loss: 1.8294\n","Average Score for this Epoch: 2.0433857440948486\n","--- new best score ---\n","\n","\n","-------------------- Epoch 71 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 2.2273\n","Iteration: 2 of 27\ttrain_loss: 1.6703\n","Iteration: 4 of 27\ttrain_loss: 2.1922\n","Iteration: 6 of 27\ttrain_loss: 1.8116\n","Iteration: 8 of 27\ttrain_loss: 1.9910\n","Iteration: 10 of 27\ttrain_loss: 1.5607\n","Iteration: 12 of 27\ttrain_loss: 1.6394\n","Iteration: 14 of 27\ttrain_loss: 1.9587\n","Iteration: 16 of 27\ttrain_loss: 1.9385\n","Iteration: 18 of 27\ttrain_loss: 2.3275\n","Iteration: 20 of 27\ttrain_loss: 1.9186\n","Iteration: 22 of 27\ttrain_loss: 2.1805\n","Iteration: 24 of 27\ttrain_loss: 1.5347\n","Iteration: 26 of 27\ttrain_loss: 1.5021\n","Iteration: 27 of 27\ttrain_loss: 2.1765\n","Average Score for this Epoch: 1.9503953456878662\n","--- new best score ---\n","\n","\n","-------------------- Epoch 72 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 2.1164\n","Iteration: 2 of 27\ttrain_loss: 1.8377\n","Iteration: 4 of 27\ttrain_loss: 1.5641\n","Iteration: 6 of 27\ttrain_loss: 2.1670\n","Iteration: 8 of 27\ttrain_loss: 1.6538\n","Iteration: 10 of 27\ttrain_loss: 2.2294\n","Iteration: 12 of 27\ttrain_loss: 1.9295\n","Iteration: 14 of 27\ttrain_loss: 2.4256\n","Iteration: 16 of 27\ttrain_loss: 1.8736\n","Iteration: 18 of 27\ttrain_loss: 2.1187\n","Iteration: 20 of 27\ttrain_loss: 2.4785\n","Iteration: 22 of 27\ttrain_loss: 1.8546\n","Iteration: 24 of 27\ttrain_loss: 2.1507\n","Iteration: 26 of 27\ttrain_loss: 2.0616\n","Iteration: 27 of 27\ttrain_loss: 2.0968\n","Average Score for this Epoch: 1.9663180112838745\n","-------------------- Epoch 73 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 1.8118\n","Iteration: 2 of 27\ttrain_loss: 1.6774\n","Iteration: 4 of 27\ttrain_loss: 1.5656\n","Iteration: 6 of 27\ttrain_loss: 1.8915\n","Iteration: 8 of 27\ttrain_loss: 1.9306\n","Iteration: 10 of 27\ttrain_loss: 2.5392\n","Iteration: 12 of 27\ttrain_loss: 1.9885\n","Iteration: 14 of 27\ttrain_loss: 2.3686\n","Iteration: 16 of 27\ttrain_loss: 1.8065\n","Iteration: 18 of 27\ttrain_loss: 2.2282\n","Iteration: 20 of 27\ttrain_loss: 2.7238\n","Iteration: 22 of 27\ttrain_loss: 2.0280\n","Iteration: 24 of 27\ttrain_loss: 2.3181\n","Iteration: 26 of 27\ttrain_loss: 1.8319\n","Iteration: 27 of 27\ttrain_loss: 1.9086\n","Average Score for this Epoch: 2.007852554321289\n","-------------------- Epoch 74 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 1.8431\n","Iteration: 2 of 27\ttrain_loss: 1.8644\n","Iteration: 4 of 27\ttrain_loss: 1.8258\n","Iteration: 6 of 27\ttrain_loss: 1.6839\n","Iteration: 8 of 27\ttrain_loss: 2.1910\n","Iteration: 10 of 27\ttrain_loss: 2.0025\n","Iteration: 12 of 27\ttrain_loss: 2.1409\n","Iteration: 14 of 27\ttrain_loss: 2.1032\n","Iteration: 16 of 27\ttrain_loss: 2.8355\n","Iteration: 18 of 27\ttrain_loss: 2.3073\n","Iteration: 20 of 27\ttrain_loss: 2.2023\n","Iteration: 22 of 27\ttrain_loss: 1.6188\n","Iteration: 24 of 27\ttrain_loss: 1.7111\n","Iteration: 26 of 27\ttrain_loss: 1.5773\n","Iteration: 27 of 27\ttrain_loss: 2.3371\n","Average Score for this Epoch: 2.0594844818115234\n","-------------------- Epoch 75 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 2.0683\n","Iteration: 2 of 27\ttrain_loss: 1.9075\n","Iteration: 4 of 27\ttrain_loss: 2.1731\n","Iteration: 6 of 27\ttrain_loss: 1.9555\n","Iteration: 8 of 27\ttrain_loss: 1.9778\n","Iteration: 10 of 27\ttrain_loss: 1.9905\n","Iteration: 12 of 27\ttrain_loss: 2.5921\n","Iteration: 14 of 27\ttrain_loss: 1.5803\n","Iteration: 16 of 27\ttrain_loss: 2.2307\n","Iteration: 18 of 27\ttrain_loss: 2.1278\n","Iteration: 20 of 27\ttrain_loss: 1.8734\n","Iteration: 22 of 27\ttrain_loss: 1.9333\n","Iteration: 24 of 27\ttrain_loss: 2.8367\n","Iteration: 26 of 27\ttrain_loss: 1.8896\n","Iteration: 27 of 27\ttrain_loss: 2.2435\n","Average Score for this Epoch: 2.0551507472991943\n","-------------------- Epoch 76 of 100 --------------------\n","Iteration: 0 of 27\ttrain_loss: 1.5088\n","Iteration: 2 of 27\ttrain_loss: 1.8793\n","Iteration: 4 of 27\ttrain_loss: 1.4545\n","Iteration: 6 of 27\ttrain_loss: 2.7178\n","Iteration: 8 of 27\ttrain_loss: 1.7161\n","Iteration: 10 of 27\ttrain_loss: 2.0989\n","Iteration: 12 of 27\ttrain_loss: 2.1299\n","Iteration: 14 of 27\ttrain_loss: 1.4315\n","Iteration: 16 of 27\ttrain_loss: 2.7222\n","Iteration: 18 of 27\ttrain_loss: 2.1815\n","Iteration: 20 of 27\ttrain_loss: 2.2712\n","Iteration: 22 of 27\ttrain_loss: 2.0192\n","Iteration: 24 of 27\ttrain_loss: 3.2248\n","Iteration: 26 of 27\ttrain_loss: 2.1378\n","Iteration: 27 of 27\ttrain_loss: 1.3292\n","Average Score for this Epoch: 2.0072360038757324\n","- early stopping 5 epochs without improvement\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gk50L1W96yff","colab_type":"code","outputId":"44390a47-c0b7-4d15-b72b-ecc90942ef9b","colab":{"base_uri":"https://localhost:8080/","height":326},"executionInfo":{"status":"ok","timestamp":1556964081350,"user_tz":-330,"elapsed":6452,"user":{"displayName":"arpit.jain arpit.jain","photoUrl":"https://lh5.googleusercontent.com/-cBrzJn4bZ70/AAAAAAAAAAI/AAAAAAAAA4k/GAn2TH00IbM/s64/photo.jpg","userId":"08694739481247522869"}}},"source":["reset_graph()\n","summarizer = Summarizer(word2ind,\n","                                   ind2word,\n","                                   './models/headlines/my_model',\n","                                   'INFER',\n","                                   num_layers_encoder = num_layers_encoder,\n","                                   num_layers_decoder = num_layers_decoder,\n","                                   batch_size = len(converted_texts[:50]),\n","                                   clip = clip,\n","                                   keep_probability = 1.0,\n","                                   learning_rate = 0.0,\n","                                   beam_width = 5,\n","                                   rnn_size_encoder = rnn_size_encoder,\n","                                   rnn_size_decoder = rnn_size_decoder,\n","                                   inference_targets = False,\n","                                   pretrained_embeddings_path = pretrained_embeddings_path)\n","\n","summarizer.build_graph()\n","preds = summarizer.infer(converted_texts[:50],\n","                         restore_path =  './models/headlines/my_model',\n","                         targets = converted_summaries[:50])\n"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Loaded pretrained embeddings.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/seq2seq/python/ops/beam_search_decoder.py:733: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n"],"name":"stdout"},{"output_type":"stream","text":["W0504 10:01:26.384288 140572899837824 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/seq2seq/python/ops/beam_search_decoder.py:733: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n"],"name":"stderr"},{"output_type":"stream","text":["Graph built.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n"],"name":"stdout"},{"output_type":"stream","text":["W0504 10:01:27.005825 140572899837824 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Restoring parameters from ./models/headlines/my_model\n"],"name":"stdout"},{"output_type":"stream","text":["I0504 10:01:27.009449 140572899837824 saver.py:1270] Restoring parameters from ./models/headlines/my_model\n"],"name":"stderr"},{"output_type":"stream","text":["Done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7LVaQsLt65ou","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":8027},"outputId":"0d0804fa-3276-42e3-f240-3c11bc31cd48","executionInfo":{"status":"ok","timestamp":1556964083225,"user_tz":-330,"elapsed":1180,"user":{"displayName":"arpit.jain arpit.jain","photoUrl":"https://lh5.googleusercontent.com/-cBrzJn4bZ70/AAAAAAAAAAI/AAAAAAAAA4k/GAn2TH00IbM/s64/photo.jpg","userId":"08694739481247522869"}}},"source":["sample_results(preds,\n","                                      ind2word,\n","                                      word2ind,\n","                                      converted_summaries[:30],\n","                                      converted_texts[:30],\n","                                      use_rouge = True)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["\n","\n","\n"," ----------------------------------------------------------------------------------------------------\n","Actual Text:\n","in major abortion ruling monday the supreme court struck down parts of texas law that would have forced dozens of clinics to close here are reactions from all sides of the issue\n","\n","Actual Summary:\n","reactions to the supreme court ruling on texas abortion law\n","\n","Created Summary:\n","reactions to to supreme court ruling on texas abortion law\n","\n","Rogue-score: {'rouge-1': {'f': 0.9473684160664821, 'p': 1.0, 'r': 0.9}, 'rouge-2': {'f': 0.7777777727777778, 'p': 0.7777777777777778, 'r': 0.7777777777777778}, 'rouge-l': {'f': 0.9421631000574496, 'p': 1.0, 'r': 0.9}}\n","\n","\n","\n","\n"," ----------------------------------------------------------------------------------------------------\n","Actual Text:\n","christmas jams at the tunnel chop through hustle and bustle snow and lights make wonderland out of this concrete jungle mary blige christmas in the city\n","\n","Actual Summary:\n","voyeur christmas trees\n","\n","Created Summary:\n","voyeur christmas trees\n","\n","Rogue-score: {'rouge-1': {'f': 0.999999995, 'p': 1.0, 'r': 1.0}, 'rouge-2': {'f': 0.999999995, 'p': 1.0, 'r': 1.0}, 'rouge-l': {'f': 0.9999999999995, 'p': 1.0, 'r': 1.0}}\n","\n","\n","\n","\n"," ----------------------------------------------------------------------------------------------------\n","Actual Text:\n","paris ap facebook says it has targeted 30 000 fake accounts linked to france ahead of the country presidential election as part of worldwide effort against misinformation advertisement\n","\n","Actual Summary:\n","facebook targets 30 000 fake french accounts before election\n","\n","Created Summary:\n","facebook targets 30 000 fake french accounts before before\n","\n","Rogue-score: {'rouge-1': {'f': 0.9411764656055364, 'p': 1.0, 'r': 0.8888888888888888}, 'rouge-2': {'f': 0.874999995, 'p': 0.875, 'r': 0.875}, 'rouge-l': {'f': 0.9347300564057505, 'p': 1.0, 'r': 0.8888888888888888}}\n","\n","\n","\n","\n"," ----------------------------------------------------------------------------------------------------\n","Actual Text:\n","san francisco ap apple penalized ceo tim cook for the iphone maker first sales slump in 15 years with 15 percent pay cut advertisement\n","\n","Actual Summary:\n","apple ceo tim cook pay slumps along with iphone sales\n","\n","Created Summary:\n","apple ceo tim cook pay slumps along with iphone sales\n","\n","Rogue-score: {'rouge-1': {'f': 0.999999995, 'p': 1.0, 'r': 1.0}, 'rouge-2': {'f': 0.999999995, 'p': 1.0, 'r': 1.0}, 'rouge-l': {'f': 0.9999999999995, 'p': 1.0, 'r': 1.0}}\n","\n","\n","\n","\n"," ----------------------------------------------------------------------------------------------------\n","Actual Text:\n","on friday broadcast of hbo real time jane fonda stated she won call president donald trump by his name call him the follow ian hanchett on twitter ianhanchett\n","\n","Actual Summary:\n","jane fonda won call trump by his name call him the predator in chief\n","\n","Created Summary:\n","jane fonda won call trump call call call call him him predator chief chief\n","\n","Rogue-score: {'rouge-1': {'f': 0.7619047571882087, 'p': 1.0, 'r': 0.6153846153846154}, 'rouge-2': {'f': 0.4166666617013889, 'p': 0.45454545454545453, 'r': 0.38461538461538464}, 'rouge-l': {'f': 0.6880767811000172, 'p': 1.0, 'r': 0.6153846153846154}}\n","\n","\n","\n","\n"," ----------------------------------------------------------------------------------------------------\n","Actual Text:\n","platinum games is bringing nier automata the sequel to action rpg nier to the playstation 4 on march 7 as players fight extraterrestrial machines as android protectors of humanity\n","\n","Actual Summary:\n","nier automata glory to mankind trailer\n","\n","Created Summary:\n","nier automata glory to mankind trailer\n","\n","Rogue-score: {'rouge-1': {'f': 0.999999995, 'p': 1.0, 'r': 1.0}, 'rouge-2': {'f': 0.999999995, 'p': 1.0, 'r': 1.0}, 'rouge-l': {'f': 0.9999999999995, 'p': 1.0, 'r': 1.0}}\n","\n","\n","\n","\n"," ----------------------------------------------------------------------------------------------------\n","Actual Text:\n","president donald trump recent defense of israel at the united nations is almost unprecedented and warrants the appreciation and gratitude of the american jewish and community advertisement\n","\n","Actual Summary:\n","rabbi shmuley will aipac honor trump defense of israel at the un\n","\n","Created Summary:\n","rabbi shmuley will aipac honor defense defense of israel at un un\n","\n","Rogue-score: {'rouge-1': {'f': 0.9090909041322315, 'p': 1.0, 'r': 0.8333333333333334}, 'rouge-2': {'f': 0.6363636313636364, 'p': 0.6363636363636364, 'r': 0.6363636363636364}, 'rouge-l': {'f': 0.894428152492368, 'p': 1.0, 'r': 0.8333333333333334}}\n","\n","\n","\n","\n"," ----------------------------------------------------------------------------------------------------\n","Actual Text:\n","experience the battlefield in 360 with this interactive trailer for ubisoft upcoming vikings vs knights vs samurai brawler for honor\n","\n","Actual Summary:\n","for honor 360 trailer in the heart of battle\n","\n","Created Summary:\n","for honor 360 the in heart heart battle battle\n","\n","Rogue-score: {'rouge-1': {'f': 0.8749999950781251, 'p': 1.0, 'r': 0.7777777777777778}, 'rouge-2': {'f': 0.24999999500000009, 'p': 0.25, 'r': 0.25}, 'rouge-l': {'f': 0.7276119402982826, 'p': 0.8571428571428571, 'r': 0.6666666666666666}}\n","\n","\n","\n","\n"," ----------------------------------------------------------------------------------------------------\n","Actual Text:\n","geneva ap an italian train derailed in the central swiss city of lucerne on wednesday and one carriage tipped over injuring seven people on board advertisement\n","\n","Actual Summary:\n","italian train derails in switzerland seven injured\n","\n","Created Summary:\n","italian train derails in switzerland seven injured\n","\n","Rogue-score: {'rouge-1': {'f': 0.999999995, 'p': 1.0, 'r': 1.0}, 'rouge-2': {'f': 0.999999995, 'p': 1.0, 'r': 1.0}, 'rouge-l': {'f': 0.9999999999995, 'p': 1.0, 'r': 1.0}}\n","\n","\n","\n","\n"," ----------------------------------------------------------------------------------------------------\n","Actual Text:\n","budapest hungary ap hungary governing party says that it will propose legislation forcing organizations reveal the source amount and aim of foreign funding they receive advertisement\n","\n","Actual Summary:\n","hungary all ngos should declare foreign funding including soros money\n","\n","Created Summary:\n","hungary all ngos should declare foreign funding including soros money\n","\n","Rogue-score: {'rouge-1': {'f': 0.999999995, 'p': 1.0, 'r': 1.0}, 'rouge-2': {'f': 0.999999995, 'p': 1.0, 'r': 1.0}, 'rouge-l': {'f': 0.9999999999995, 'p': 1.0, 'r': 1.0}}\n","\n","\n","\n","\n"," ----------------------------------------------------------------------------------------------------\n","Actual Text:\n","thought was impervious to hateful leftist rhetoric milo told breitbart news but this makes me rethink everything maybe should just cancel the tour there no coming back from this\n","\n","Actual Summary:\n","milo finally stumped by hateful left wing protest sign\n","\n","Created Summary:\n","milo finally stumped by hateful left wing protest sign\n","\n","Rogue-score: {'rouge-1': {'f': 0.999999995, 'p': 1.0, 'r': 1.0}, 'rouge-2': {'f': 0.999999995, 'p': 1.0, 'r': 1.0}, 'rouge-l': {'f': 0.9999999999995, 'p': 1.0, 'r': 1.0}}\n","\n","\n","\n","\n"," ----------------------------------------------------------------------------------------------------\n","Actual Text:\n","rome ap police in greece have arrested three pakistani nationals for holding hostage 16 migrants without authorization to be in the country and demanding money for their release\n","\n","Actual Summary:\n","pakistani nationals arrested for holding migrants hostage\n","\n","Created Summary:\n","pakistani nationals arrested arrested holding migrants hostage\n","\n","Rogue-score: {'rouge-1': {'f': 0.9230769181065088, 'p': 1.0, 'r': 0.8571428571428571}, 'rouge-2': {'f': 0.6666666616666668, 'p': 0.6666666666666666, 'r': 0.6666666666666666}, 'rouge-l': {'f': 0.9123434704826733, 'p': 1.0, 'r': 0.8571428571428571}}\n","\n","\n","\n","\n"," ----------------------------------------------------------------------------------------------------\n","Actual Text:\n","new york ap many people have heard of twitter not enough of them are signing up to use it advertisement\n","\n","Actual Summary:\n","celebrity megaphone fails to lure ordinary users to twitter\n","\n","Created Summary:\n","new megaphone fails to lure ordinary users to twitter\n","\n","Rogue-score: {'rouge-1': {'f': 0.874999995, 'p': 0.875, 'r': 0.875}, 'rouge-2': {'f': 0.874999995, 'p': 0.875, 'r': 0.875}, 'rouge-l': {'f': 0.8749999999995, 'p': 0.875, 'r': 0.875}}\n","\n","\n","\n","\n"," ----------------------------------------------------------------------------------------------------\n","Actual Text:\n","paris ap paris police say letter bomb exploded at the french office of the international monetary fund lightly injuring one person advertisement\n","\n","Actual Summary:\n","letter bomb injures one at imf paris office\n","\n","Created Summary:\n","letter bomb injures in at imf office office\n","\n","Rogue-score: {'rouge-1': {'f': 0.7999999950222222, 'p': 0.8571428571428571, 'r': 0.75}, 'rouge-2': {'f': 0.4285714235714286, 'p': 0.42857142857142855, 'r': 0.42857142857142855}, 'rouge-l': {'f': 0.7929824561399953, 'p': 0.8571428571428571, 'r': 0.75}}\n","\n","\n","\n","\n"," ----------------------------------------------------------------------------------------------------\n","Actual Text:\n","the latest trailer for horizon zero dawn explores the weapons equipment and combat styles available to players in the forthcoming rpg\n","\n","Actual Summary:\n","the combat of horizon zero dawn trailer\n","\n","Created Summary:\n","the combat of horizon zero dawn trailer\n","\n","Rogue-score: {'rouge-1': {'f': 0.999999995, 'p': 1.0, 'r': 1.0}, 'rouge-2': {'f': 0.999999995, 'p': 1.0, 'r': 1.0}, 'rouge-l': {'f': 0.9999999999995, 'p': 1.0, 'r': 1.0}}\n","\n","\n","\n","\n"," ----------------------------------------------------------------------------------------------------\n","Actual Text:\n","paris ap emmanuel macron and marine le pen are preparing for their televised french presidential election debate with much at stake for both contenders advertisement\n","\n","Actual Summary:\n","france macron and le pen to face off in crucial pre election tv debate\n","\n","Created Summary:\n","france macron and le pen face face in crucial pre pre pre tv\n","\n","Rogue-score: {'rouge-1': {'f': 0.8333333284722222, 'p': 1.0, 'r': 0.7142857142857143}, 'rouge-2': {'f': 0.4999999950347222, 'p': 0.5454545454545454, 'r': 0.46153846153846156}, 'rouge-l': {'f': 0.7905982905981517, 'p': 1.0, 'r': 0.7142857142857143}}\n","\n","\n","\n","\n"," ----------------------------------------------------------------------------------------------------\n","Actual Text:\n","check out the latest gameplay from the upcoming the legend of zelda breath of the wild shown during the nintendo switch presentation\n","\n","Actual Summary:\n","the legend of zelda breath of the wild nintendo switch presentation trailer\n","\n","Created Summary:\n","the legend of zelda breath of the wild wild nintendo presentation presentation\n","\n","Rogue-score: {'rouge-1': {'f': 0.8888888839506174, 'p': 1.0, 'r': 0.8}, 'rouge-2': {'f': 0.7272727222727273, 'p': 0.7272727272727273, 'r': 0.7272727272727273}, 'rouge-l': {'f': 0.8677248677246125, 'p': 1.0, 'r': 0.8}}\n","\n","\n","\n","\n"," ----------------------------------------------------------------------------------------------------\n","Actual Text:\n","frankfort <UNK> ap apple says it will give 200 million to corning inc so it can invest in kentucky plant that makes glass screens for iphones and ipads advertisement\n","\n","Actual Summary:\n","apple to spend 200 million supporting corning plant in kentucky\n","\n","Created Summary:\n","apple to spend 200 supporting supporting corning plant in\n","\n","Rogue-score: {'rouge-1': {'f': 0.8888888839506174, 'p': 1.0, 'r': 0.8}, 'rouge-2': {'f': 0.7058823479584776, 'p': 0.75, 'r': 0.6666666666666666}, 'rouge-l': {'f': 0.8677248677246125, 'p': 1.0, 'r': 0.8}}\n","\n","\n","\n","\n"," ----------------------------------------------------------------------------------------------------\n","Actual Text:\n","moscow ap trial for the blogger who is accused of inciting religious hatred for playing pokemon go in church has begun in the russian city of yekaterinburg advertisement\n","\n","Actual Summary:\n","blogger goes on trial for playing pokemon go in russian church\n","\n","Created Summary:\n","blogger goes on trial for playing pokemon go in russian\n","\n","Rogue-score: {'rouge-1': {'f': 0.9523809473922903, 'p': 1.0, 'r': 0.9090909090909091}, 'rouge-2': {'f': 0.9473684160664821, 'p': 1.0, 'r': 0.9}, 'rouge-l': {'f': 0.9480909480905495, 'p': 1.0, 'r': 0.9090909090909091}}\n","\n","\n","\n","\n"," ----------------------------------------------------------------------------------------------------\n","Actual Text:\n","cleveland ap the man who randomly killed cleveland retiree and posted video of the crime on facebook shot himself to death on tuesday in pennsylvania police said advertisement\n","\n","Actual Summary:\n","police facebook live murder suspect steve stephens killed himself during pursuit\n","\n","Created Summary:\n","police police officer murder suspect steve stephens stephens himself himself pursuit\n","\n","Rogue-score: {'rouge-1': {'f': 0.7368421003878117, 'p': 0.875, 'r': 0.6363636363636364}, 'rouge-2': {'f': 0.2999999950000001, 'p': 0.3, 'r': 0.3}, 'rouge-l': {'f': 0.7026587086270818, 'p': 0.875, 'r': 0.6363636363636364}}\n","\n","\n","\n","\n"," ----------------------------------------------------------------------------------------------------\n","Actual Text:\n","fight to liberate italy as wwii allied sniper in singleplayer and multiplayer in sniper elite 4 coming to xbox one playstation 4 and pc on february 14\n","\n","Actual Summary:\n","sniper elite 4 101 gameplay trailer\n","\n","Created Summary:\n","sniper elite 4 101 gameplay trailer\n","\n","Rogue-score: {'rouge-1': {'f': 0.999999995, 'p': 1.0, 'r': 1.0}, 'rouge-2': {'f': 0.999999995, 'p': 1.0, 'r': 1.0}, 'rouge-l': {'f': 0.9999999999995, 'p': 1.0, 'r': 1.0}}\n","\n","\n","\n","\n"," ----------------------------------------------------------------------------------------------------\n","Actual Text:\n","new york ap google is now directing its review teams to flag content that might come across as upsetting or offensive in search results advertisement\n","\n","Actual Summary:\n","google adds tool to flag offensive search results\n","\n","Created Summary:\n","google adds tool to flag offensive search\n","\n","Rogue-score: {'rouge-1': {'f': 0.9333333283555556, 'p': 1.0, 'r': 0.875}, 'rouge-2': {'f': 0.9230769181065088, 'p': 1.0, 'r': 0.8571428571428571}, 'rouge-l': {'f': 0.9251461988300539, 'p': 1.0, 'r': 0.875}}\n","\n","\n","\n","\n"," ----------------------------------------------------------------------------------------------------\n","Actual Text:\n","president donald trump was the primary target for leftist hollywood celebrities during the oscars as he his family or his administration was mentioned negatively fifteen times during the ceremony\n","\n","Actual Summary:\n","hollywood celebrities attack donald trump 15 times at oscars\n","\n","Created Summary:\n","hollywood celebrities attack donald trump 15 15 at oscars\n","\n","Rogue-score: {'rouge-1': {'f': 0.9411764656055364, 'p': 1.0, 'r': 0.8888888888888888}, 'rouge-2': {'f': 0.749999995, 'p': 0.75, 'r': 0.75}, 'rouge-l': {'f': 0.9347300564057505, 'p': 1.0, 'r': 0.8888888888888888}}\n","\n","\n","\n","\n"," ----------------------------------------------------------------------------------------------------\n","Actual Text:\n","mexico city ap mexico top diplomat said monday his country will spend about 50 million to hire lawyers for migrants in the united states facing deportation advertisement\n","\n","Actual Summary:\n","mexico vows 50 million legal fund to fight deportations\n","\n","Created Summary:\n","mexico vows 50 million legal fund to fight deportations\n","\n","Rogue-score: {'rouge-1': {'f': 0.999999995, 'p': 1.0, 'r': 1.0}, 'rouge-2': {'f': 0.999999995, 'p': 1.0, 'r': 1.0}, 'rouge-l': {'f': 0.9999999999995, 'p': 1.0, 'r': 1.0}}\n","\n","\n","\n","\n"," ----------------------------------------------------------------------------------------------------\n","Actual Text:\n","business advocates who want to import more foreign consumers and more foreign workers are developing plans to counter president donald trump popular call for immigration reform advertisement\n","\n","Actual Summary:\n","gop senators hope to sneak amnesty into trump popular immigration reforms\n","\n","Created Summary:\n","gop senators hope to sneak amnesty to popular popular reforms reforms\n","\n","Rogue-score: {'rouge-1': {'f': 0.8421052582825486, 'p': 1.0, 'r': 0.7272727272727273}, 'rouge-2': {'f': 0.4999999950000001, 'p': 0.5, 'r': 0.5}, 'rouge-l': {'f': 0.8030385241452588, 'p': 1.0, 'r': 0.7272727272727273}}\n","\n","\n","\n","\n"," ----------------------------------------------------------------------------------------------------\n","Actual Text:\n","berlin ap pope francis has warned in an interview with german newspaper of the dangers of rising populism in western democracies advertisement\n","\n","Actual Summary:\n","pope slams rise of evil populism in western democracies\n","\n","Created Summary:\n","pope slams rise of evil populism in western democracies\n","\n","Rogue-score: {'rouge-1': {'f': 0.999999995, 'p': 1.0, 'r': 1.0}, 'rouge-2': {'f': 0.999999995, 'p': 1.0, 'r': 1.0}, 'rouge-l': {'f': 0.9999999999995, 'p': 1.0, 'r': 1.0}}\n","\n","\n","\n","\n"," ----------------------------------------------------------------------------------------------------\n","Actual Text:\n","berlin ap federal prosecutors say they have charged german man with membership in terrorist organization for joining the islamic state group in syria advertisement\n","\n","Actual Summary:\n","german prosecutors charge man with islamic state membership\n","\n","Created Summary:\n","german prosecutors charge man with islamic state membership\n","\n","Rogue-score: {'rouge-1': {'f': 0.999999995, 'p': 1.0, 'r': 1.0}, 'rouge-2': {'f': 0.999999995, 'p': 1.0, 'r': 1.0}, 'rouge-l': {'f': 0.9999999999995, 'p': 1.0, 'r': 1.0}}\n","\n","\n","\n","\n"," ----------------------------------------------------------------------------------------------------\n","Actual Text:\n","the senate voted to confirm former exxon ceo rex tillerson as president donald trump secretary of state wednesday afternoon <UNK> to 43 advertisement\n","\n","Actual Summary:\n","senate confirms rex tillerson as secretary of state\n","\n","Created Summary:\n","senate confirms rex tillerson as secretary state\n","\n","Rogue-score: {'rouge-1': {'f': 0.9333333283555556, 'p': 1.0, 'r': 0.875}, 'rouge-2': {'f': 0.7692307642603551, 'p': 0.8333333333333334, 'r': 0.7142857142857143}, 'rouge-l': {'f': 0.9251461988300539, 'p': 1.0, 'r': 0.875}}\n","\n","\n","\n","\n"," ----------------------------------------------------------------------------------------------------\n","Actual Text:\n","berlin ap german chancellor angela merkel is likely to meet with vice president mike pence next week advertisement\n","\n","Actual Summary:\n","germany merkel to meet trump vice president pence next week\n","\n","Created Summary:\n","germany merkel to trump trump vice the next\n","\n","Rogue-score: {'rouge-1': {'f': 0.7058823480968859, 'p': 0.8571428571428571, 'r': 0.6}, 'rouge-2': {'f': 0.37499999507812504, 'p': 0.42857142857142855, 'r': 0.3333333333333333}, 'rouge-l': {'f': 0.6656738644823815, 'p': 0.8571428571428571, 'r': 0.6}}\n","\n","\n","\n","\n"," ----------------------------------------------------------------------------------------------------\n","Actual Text:\n","on friday broadcast of hbo real time jane fonda declared have to include race and class in everything we do as we go forward follow ian hanchett on twitter ianhanchett\n","\n","Actual Summary:\n","jane fonda have to include race and class in everything we do\n","\n","Created Summary:\n","jane fonda have to include race and class and everything we do\n","\n","Rogue-score: {'rouge-1': {'f': 0.9565217341398866, 'p': 1.0, 'r': 0.9166666666666666}, 'rouge-2': {'f': 0.8181818131818183, 'p': 0.8181818181818182, 'r': 0.8181818181818182}, 'rouge-l': {'f': 0.9529257927423186, 'p': 1.0, 'r': 0.9166666666666666}}\n","\n","\n","Average Rouge (Recall-Oriented Understudy for Gisting Evaluation) Scores:\n","\n","ROUGE-1: \n","\n","Precision:  0.9821428571428572\n","Recall:  0.8746698671698673\n","F-Score:  0.9215101332729613\n","\n","ROUGE-2: \n","\n","Precision:  0.7872246272246272\n","Recall:  0.764080549080549\n","F-Score:  0.7747353012680038\n","\n","ROUGE-L: \n","\n","Precision:  0.9773809523809525\n","Recall:  0.8709661634661636\n","F-Score:  0.9050264758390452\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GD2iRovenOmj","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}